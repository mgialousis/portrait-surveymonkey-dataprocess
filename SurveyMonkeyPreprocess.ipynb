{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60cdcd59323440ca",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4ef98726c18ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import platform\n",
    "\n",
    "# Configuration\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f5dd4ab8496b63",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44e57470c1d6bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "DATA_DIR = Path(\"data\")\n",
    "#INPUT_FILENAME = DATA_DIR / \"PORTRAIT_last.csv\"\n",
    "#OUTPUT_FILENAME = DATA_DIR / \"PORTRAIT_last_updated.csv\"\n",
    "INPUT_FILENAME = DATA_DIR / \"phq.csv\"\n",
    "OUTPUT_FILENAME = DATA_DIR / \"phq_updated.csv\"\n",
    "\n",
    "# Column names\n",
    "RESPONDENT_ID = \"respondent_id\"\n",
    "USER_CODE = \"Código de usuario\"\n",
    "GENDER = (\n",
    "    \"¿Con qué género se identifica más usted? \"\n",
    "    \"(Selecciona la opción que más te identifique)\"\n",
    ")\n",
    "\n",
    "# Users to exclude\n",
    "USERS_TO_REMOVE = {\n",
    "    \"1XIH2\", \"B1Q2C\", \"KY12C\", \"QO12D\", \"S1HA2\",\n",
    "    \"XZ21K\", \"21WYJ\", \"B21DT\",\n",
    "}\n",
    "\n",
    "# Duplicate users to remove (user_code: respondent_id)\n",
    "DUPLICATES_TO_REMOVE = {\n",
    "    \"1H2GG\": \"118898041284\",\n",
    "    \"IC21Y\": \"118919025758\",\n",
    "    \"B2I1M\": \"118915917238\",\n",
    "    \"1Y2ZF\": \"118877646327\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc195b489d73151c",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4cd5349ab2a461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_column_index(header_row: pd.Series, target_value: str) -> int:\n",
    "    \"\"\"Find index of target_value in header_row.\n",
    "\n",
    "    Args:\n",
    "        header_row: Pandas Series containing column headers\n",
    "        target_value: String to find in header_row\n",
    "\n",
    "    Returns:\n",
    "        int: Index of the target value\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If target_value is not found in header_row\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return header_row.tolist().index(target_value)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(\n",
    "            f\"Header value '{target_value}' not found in DataFrame header.\\n\"\n",
    "            f\"Available headers: {header_row.tolist()}\"\n",
    "        ) from e\n",
    "\n",
    "def clean_user_code(df: pd.DataFrame, user_col_idx: int) -> None:\n",
    "    \"\"\"Clean and standardize user codes in the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        user_col_idx: Index of the user code column\n",
    "    \"\"\"\n",
    "    df.iloc[3:, user_col_idx] = (\n",
    "        df.iloc[3:, user_col_idx]\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .str.upper()\n",
    "    )\n",
    "\n",
    "def remove_duplicate_users(\n",
    "    df: pd.DataFrame,\n",
    "    user_col_idx: int,\n",
    "    dupes: Dict[str, str]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Remove duplicate users based on user code and respondent ID.\n",
    "\n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        user_col_idx: Index of the user code column\n",
    "        dupes: Dictionary mapping user codes to respondent IDs to remove\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with duplicates removed\n",
    "    \"\"\"\n",
    "    mask = ~(\n",
    "        (df.iloc[:, user_col_idx].isin(dupes.keys())) &\n",
    "        (df[df.columns[0]].astype(str).isin(dupes.values()))\n",
    "    )\n",
    "    return df[mask].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d694e2ffe16ee2",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee444d19160fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure data directory exists\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Read the raw data\n",
    "print(f\"Reading data from {INPUT_FILENAME}...\")\n",
    "df = pd.read_csv(INPUT_FILENAME, header=None)\n",
    "\n",
    "# Add sequence numbers as first row\n",
    "seq_df = pd.DataFrame([range(1, df.shape[1] + 1)])\n",
    "df = pd.concat([seq_df, df], ignore_index=True)\n",
    "\n",
    "# Display initial data info\n",
    "print(f\"Initial data shape: {df.shape}\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c39705912b4e42f",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8d455c3390de63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find column indices\n",
    "try:\n",
    "    user_col_idx = find_column_index(df.iloc[1], USER_CODE)\n",
    "    print(f\"Found columns: user_code at index {user_col_idx}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error finding required columns: {e}\")\n",
    "    raise\n",
    "\n",
    "# Clean and standardize user codes\n",
    "clean_user_code(df, user_col_idx)\n",
    "\n",
    "# Remove duplicate users\n",
    "df = remove_duplicate_users(df, user_col_idx, DUPLICATES_TO_REMOVE)\n",
    "\n",
    "# Remove users in the exclusion list\n",
    "df = df[~df.iloc[:, user_col_idx].isin(USERS_TO_REMOVE)]\n",
    "\n",
    "# EXTRA CASES\n",
    "# Change usrername 02E1T to O2E1T\n",
    "df.iloc[3:, user_col_idx] = df.iloc[3:, user_col_idx].replace(\"02E1T\", \"O2E1T\")\n",
    "\n",
    "# Save processed data\n",
    "df.to_csv(OUTPUT_FILENAME, index=False, header=False)\n",
    "print(f\"Processed data saved to {OUTPUT_FILENAME}\")\n",
    "print(f\"Number of participants: {len(df) - 3}\")\n",
    "\n",
    "# Display the cleaned data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa299cdc916e6be0",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec75480b0919bce3",
   "metadata": {},
   "source": [
    "# Read updated csv and initialize needed variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf03a1c3ceb9984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the updated CSV file\n",
    "df = pd.read_csv(OUTPUT_FILENAME, header=None)\n",
    "header_row = df.iloc[0]\n",
    "subheader_row    = df.iloc[1]   # e.g. contains \"Durante las últimas dos semanas…\", “Código de usuario”, etc.\n",
    "subsubheader_row = df.iloc[2]   # e.g. contains \"Little interest…\", “Ninguna de las anteriores”, etc.\n",
    "user_col_index = find_column_index(subheader_row, \"Código de usuario\")\n",
    "\n",
    "# Define all test configurations\n",
    "TEST_CONFIG = {\n",
    "    \"PHQ\": {\n",
    "        \"header\": \"Durante las últimas dos semanas ¿con qué frecuencia ha tenido molestias debido a los siguientes problemas?\",\n",
    "        \"end_marker\": \"Si marcó cualquiera de los problemas, ¿qué tanta dificultad le han dado estos problemas para hacer su trabajo, encargarse de las tareas del hogar, o llevarse bien con otras personas?\",\n",
    "        \"end_marker_row\": \"subheader\",\n",
    "        \"end_adjustment\": -1,  # Adjust end index by -1 for PHQ\n",
    "        \"range\": (0, 3),\n",
    "        \"description\": \"Patient Health Questionnaire\"\n",
    "    },\n",
    "    \"BAI\": {\n",
    "        \"header\": \"En el cuestionario hay una lista de síntomas comunes de la ansiedad. lea cada uno de los ítems atentamente, e indique cuanto le ha afectado en la última semana incluyendo hoy:\",\n",
    "        \"end_marker\": \"Con sudores, frios o calientes.\",\n",
    "        \"end_marker_row\": \"subsubheader\",\n",
    "        \"range\": (0, 3),\n",
    "        \"description\": \"Beck Anxiety Inventory\"\n",
    "    },\n",
    "}\n",
    "\n",
    "def find_test_indices(header_lookup, test_config):\n",
    "    \"\"\"Find start and end indices for a test section.\"\"\"\n",
    "    start_index = find_column_index(header_lookup, test_config[\"header\"])\n",
    "\n",
    "    # Determine which row to find the end marker in\n",
    "    if test_config.get(\"end_marker_row\") == \"subsubheader\":\n",
    "        end_row = subsubheader_row\n",
    "    else:\n",
    "        end_row = subheader_row\n",
    "\n",
    "    end_index = find_column_index(end_row, test_config[\"end_marker\"])\n",
    "\n",
    "    # Apply any adjustments to the end index\n",
    "    if \"end_adjustment\" in test_config:\n",
    "        end_index += test_config[\"end_adjustment\"]\n",
    "\n",
    "    return start_index, end_index\n",
    "\n",
    "def score_survey(df: pd.DataFrame, column_start_idx: int, column_end_idx: int) -> pd.DataFrame:\n",
    "    \"\"\"Score the survey by adjusting each question score.\n",
    "\n",
    "    Args:\n",
    "        df: Input DataFrame containing survey data\n",
    "        column_start_idx: Index of the first question column\n",
    "        column_end_idx: Index of the last question column\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with adjusted scores\n",
    "    \"\"\"\n",
    "    # Ensure indices are within the range of DataFrame columns\n",
    "    if column_start_idx < 0 or column_end_idx >= len(df.columns):\n",
    "        raise IndexError(\"Column indices are out of range\")\n",
    "\n",
    "    # Adjust scores by subtracting 1 from each question column\n",
    "    df.iloc[3:, column_start_idx:column_end_idx + 1] = (\n",
    "        df.iloc[3:, column_start_idx:column_end_idx + 1].astype(int) - 1\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "# Find all test indices\n",
    "test_indices = {}\n",
    "for test_name, config in TEST_CONFIG.items():\n",
    "    try:\n",
    "        start, end = find_test_indices(subheader_row, config)\n",
    "        test_indices[f\"{test_name.lower()}_start_index\"] = start\n",
    "        test_indices[f\"{test_name.lower()}_end_index\"] = end\n",
    "        print(f\"Found {config['description']} ({test_name}) at columns {start}-{end}\")\n",
    "        if test_name == \"BAI\":\n",
    "            # Adjust BAI scores\n",
    "            df = score_survey(df, int(start), int(end))\n",
    "    except ValueError as e:\n",
    "        print(f\"Warning: Could not find {test_name} test: {e}\")\n",
    "\n",
    "# Add standard column indices\n",
    "test_indices.update({\n",
    "    \"user_col_index\": find_column_index(subheader_row, \"Código de usuario\"),\n",
    "})\n",
    "\n",
    "# Make all indices available as variables in the notebook\n",
    "locals().update(test_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bad0f09a1ba7451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_description(test_name, test_config, start_idx, end_idx):\n",
    "    \"\"\"Generate a detailed description of the test validation.\"\"\"\n",
    "    description = f\"# Test {test_name}\\n\"\n",
    "    description += f\"- Description: {test_config.get('description', 'No description available')}\\n\"\n",
    "    description += f\"- Columns: {start_idx} to {end_idx}\\n\"\n",
    "    description += f\"- Valid range: {test_config.get('range', (0, 3))}\\n\"\n",
    "    return description\n",
    "\n",
    "def validate_test_responses(df, test_name, start_idx, end_idx, valid_range, start_row=3):\n",
    "    \"\"\"\n",
    "    Validate that all responses for a test fall within the specified range.\n",
    "    Returns: tuple of (passed, issues, detailed_report)\n",
    "    \"\"\"\n",
    "    min_val, max_val = valid_range\n",
    "    issues = []\n",
    "    detailed_report = []\n",
    "    passed = True\n",
    "\n",
    "    # Add test header to detailed report\n",
    "    detailed_report.append(f\"# Test {test_name}\")\n",
    "\n",
    "    # Check if indices are valid\n",
    "    if start_idx >= len(df.columns) or end_idx >= len(df.columns):\n",
    "        error_msg = f\"  - Error: Column indices out of bounds (max: {len(df.columns)-1})\"\n",
    "        issues.append(error_msg)\n",
    "        detailed_report.append(error_msg)\n",
    "        return False, issues, detailed_report\n",
    "\n",
    "    # Add column range info\n",
    "    detailed_report.append(f\"- Validating columns {start_idx} to {end_idx} (range: {min_val}-{max_val})\")\n",
    "\n",
    "    # Get the range of columns to check\n",
    "    cols_to_test = list(range(start_idx, end_idx + 1))\n",
    "    valid_count = 0\n",
    "    total_cells = 0\n",
    "\n",
    "    for row_idx in range(start_row, len(df)):\n",
    "        for col_idx in cols_to_test:\n",
    "            total_cells += 1\n",
    "            header_val = df.iloc[0, col_idx] if col_idx < len(df.iloc[0]) else \"N/A\"\n",
    "            cell = df.iloc[row_idx, col_idx]\n",
    "\n",
    "            # Check for missing values\n",
    "            if pd.isna(cell):\n",
    "                issue = f\"  - Row {row_idx+1}, Column {col_idx+1} (header: {header_val}) is empty\"\n",
    "                issues.append(issue)\n",
    "                detailed_report.append(issue)\n",
    "                passed = False\n",
    "                continue\n",
    "\n",
    "            # Check if value is numeric and in range\n",
    "            try:\n",
    "                value = float(cell)\n",
    "                if not (min_val <= value <= max_val):\n",
    "                    issue = f\"  - Row {row_idx+1}, Column {col_idx+1} (header: {header_val}): Value {value} out of range\"\n",
    "                    issues.append(issue)\n",
    "                    detailed_report.append(issue)\n",
    "                    passed = False\n",
    "                else:\n",
    "                    valid_count += 1\n",
    "            except (ValueError, TypeError):\n",
    "                issue = f\"  - Row {row_idx+1}, Column {col_idx+1} (header: {header_val}): Non-numeric value: {cell}\"\n",
    "                issues.append(issue)\n",
    "                detailed_report.append(issue)\n",
    "                passed = False\n",
    "\n",
    "    # Add summary to detailed report\n",
    "    if passed:\n",
    "        detailed_report.append(f\"\\n✓ All {valid_count} values are valid\")\n",
    "    else:\n",
    "        detailed_report.append(f\"\\n✗ Found {len(issues)} issues in {total_cells} cells\")\n",
    "\n",
    "    return passed, issues, detailed_report\n",
    "\n",
    "def validate_all_tests(df, test_configs, test_indices):\n",
    "    \"\"\"Validate all tests and return detailed reports.\"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for test_name, config in test_configs.items():\n",
    "        if test_name == \"ASSIST\":\n",
    "            continue  # Skip ASSIST as it has different validation rules\n",
    "\n",
    "        test_key = test_name.lower()\n",
    "        start_idx = test_indices.get(f\"{test_key}_start_index\")\n",
    "        end_idx = test_indices.get(f\"{test_key}_end_index\")\n",
    "\n",
    "        if start_idx is None or end_idx is None:\n",
    "            print(f\"Skipping {test_name}: Missing indices\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n=== Validating {test_name} ===\")\n",
    "        valid_range = config.get(\"range\", (0, 3))\n",
    "\n",
    "        # Get test description\n",
    "        test_desc = get_test_description(test_name, config, start_idx, end_idx)\n",
    "        print(test_desc)\n",
    "\n",
    "        # Run validation\n",
    "        passed, issues, detailed_report = validate_test_responses(\n",
    "            df, test_name, start_idx, end_idx, valid_range\n",
    "        )\n",
    "\n",
    "        # Print detailed report\n",
    "        print(\"\\n\".join(detailed_report))\n",
    "\n",
    "        # Store results\n",
    "        results[test_name] = {\n",
    "            \"passed\": passed,\n",
    "            \"issues\": issues,\n",
    "            \"num_issues\": len(issues),\n",
    "            \"columns\": f\"{start_idx}-{end_idx}\",\n",
    "            \"valid_range\": valid_range,\n",
    "            \"report\": detailed_report\n",
    "        }\n",
    "\n",
    "        status = \"✓ PASSED\" if passed else f\"✗ FAILED ({len(issues)} issues)\"\n",
    "        print(f\"\\n{status}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run the validation\n",
    "print(\"=== Starting Validation ===\\n\")\n",
    "validation_results = validate_all_tests(df, TEST_CONFIG, test_indices)\n",
    "\n",
    "# Print final summary\n",
    "print(\"\\n=== Final Validation Summary ===\")\n",
    "print(\"PASSED TESTS:\")\n",
    "passed_tests = [name for name, result in validation_results.items() if result[\"passed\"]]\n",
    "if passed_tests:\n",
    "    for name in passed_tests:\n",
    "        print(f\"✓ {name} (columns {validation_results[name]['columns']})\")\n",
    "else:\n",
    "    print(\"No tests passed validation.\")\n",
    "\n",
    "print(\"\\nFAILED TESTS:\")\n",
    "failed_tests = [name for name, result in validation_results.items() if not result[\"passed\"]]\n",
    "if failed_tests:\n",
    "    for name in failed_tests:\n",
    "        result = validation_results[name]\n",
    "        print(f\"✗ {name} (columns {result['columns']}): {result['num_issues']} issues\")\n",
    "else:\n",
    "    print(\"All tests passed validation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d693e099b168ebe",
   "metadata": {},
   "source": [
    "# TOTAL RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dfe7d384f6cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_test_scores(row, start_idx, end_idx, test_name):\n",
    "    \"\"\"Helper function to calculate test scores with error handling.\"\"\"\n",
    "    try:\n",
    "        scores = row[start_idx:end_idx + 1].astype(float)\n",
    "        return int(scores.sum())\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error processing {test_name} responses for user '{row[user_col_index]}': {e}\")\n",
    "\n",
    "def process_stai_scores(row, start_idx, end_idx, items_to_reverse, sex_col_index):\n",
    "    \"\"\"Process STAI scores with reverse scoring and classification.\"\"\"\n",
    "    try:\n",
    "        scores = row[start_idx:end_idx + 1].astype(float).copy()\n",
    "\n",
    "        # Apply reverse scoring\n",
    "        for item in items_to_reverse:\n",
    "            col_idx = start_idx + item\n",
    "            if not pd.isna(row[col_idx]):\n",
    "                scores.iloc[item] = 3 - int(scores.iloc[item])\n",
    "\n",
    "        total = int(scores.sum())\n",
    "        sex = row[sex_col_index]\n",
    "\n",
    "        # Classify based on gender\n",
    "        if sex == \"3\":\n",
    "            classification = \"Binary\"\n",
    "        elif (sex == \"2\" and total >= 29) or (sex == \"1\" and total >= 37):\n",
    "            classification = \"Severe\"\n",
    "        else:\n",
    "            classification = \"Low/Normal\"\n",
    "\n",
    "        return total, classification\n",
    "\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error processing STAI responses for user '{row[user_col_index]}': {e}\")\n",
    "\n",
    "def process_bfi_scores(row, start_idx, subscales, reverse_items):\n",
    "    \"\"\"Process BFI scores with reverse scoring.\"\"\"\n",
    "    try:\n",
    "        bfi_scores = {}\n",
    "        for subscale, cols in subscales.items():\n",
    "            scores = []\n",
    "            for col in cols:\n",
    "                try:\n",
    "                    value = float(row[col])\n",
    "                    # Reverse score if needed\n",
    "                    if col - start_idx + 1 in reverse_items.get(subscale, []):\n",
    "                        value = 6 - value\n",
    "                    scores.append(value)\n",
    "                except ValueError:\n",
    "                    raise ValueError(f\"Invalid BFI value in column {col}: {row[col]}\")\n",
    "            bfi_scores[subscale] = round(sum(scores) / len(scores), 2)\n",
    "        return bfi_scores\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error processing BFI responses: {e}\")\n",
    "\n",
    "def classify_phq(score):\n",
    "    \"\"\"Classify PHQ score into depression severity levels.\"\"\"\n",
    "    if score < 5: return \"Low\"\n",
    "    if score < 10: return \"Mild depression\"\n",
    "    if score < 15: return \"Moderate depression\"\n",
    "    if score < 20: return \"Moderately severe depression\"\n",
    "    return \"Severe depression\"\n",
    "\n",
    "def classify_bai(score):\n",
    "    \"\"\"Classify BAI score into anxiety levels.\"\"\"\n",
    "    if score <= 21: return \"Low anxiety\"\n",
    "    if score <= 35: return \"Moderate anxiety\"\n",
    "    return \"Potentially concerning levels of anxiety\"\n",
    "\n",
    "print(\"START\")\n",
    "# Process each user's responses\n",
    "for idx in range(3, len(df)):\n",
    "    row = df.iloc[idx]\n",
    "    username = row[user_col_index]\n",
    "    try:\n",
    "        # Calculate test scores\n",
    "        phq_total = calculate_test_scores(row, phq_start_index, phq_end_index, \"PHQ\")\n",
    "        bai_total = calculate_test_scores(row, bai_start_index, bai_end_index, \"BAI\")\n",
    "\n",
    "        # Classify scores\n",
    "        classifications = {\n",
    "            \"phq\": (phq_total, classify_phq(phq_total)),\n",
    "            \"bai\": (bai_total, classify_bai(bai_total)),\n",
    "        }\n",
    "\n",
    "        # Update dataframe with results\n",
    "        for prefix, (total, classification) in classifications.items():\n",
    "            df.at[idx, f\"{prefix}_total\"] = total\n",
    "            df.at[idx, f\"{prefix}_classification\"] = classification\n",
    "\n",
    "        # Print report\n",
    "        report = (\n",
    "            f\"{username}: PHQ Total = {phq_total} ({classifications['phq'][1]}), \"\n",
    "            f\"BAI Total = {bai_total} ({classifications['bai'][1]}), \"\n",
    "        )\n",
    "        print(report)\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Error processing {username}: {str(e)}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e2eb2d77498bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df = df[3:]\n",
    "\n",
    "# Define output files\n",
    "output_files = {\n",
    "    'excel': 'results__prescreen.xlsx',\n",
    "    'csv': 'results_prescreen.csv'\n",
    "}\n",
    "\n",
    "# Get responses and create results DataFrame\n",
    "responses_df = df[3:]\n",
    "results_cols = {\n",
    "    'username': responses_df.iloc[:, user_col_index],\n",
    "    **{col: responses_df[col] for col in [\n",
    "        'phq_total', 'phq_classification',\n",
    "        'bai_total', 'bai_classification',\n",
    "    ]}\n",
    "}\n",
    "# Add any additional assist columns here if needed (example):\n",
    "# \"assist_column\": responses_df[\"assist_column_name\"]\n",
    "\n",
    "results_df = pd.DataFrame(results_cols)\n",
    "\n",
    "results_df.to_excel(output_files['excel'], index=False)\n",
    "results_df.to_csv(output_files['csv'], index=False)\n",
    "\n",
    "print(f\"Results exported to {output_files['excel']} and {output_files['csv']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49687b670d1f6796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
