{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60cdcd59323440ca",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4ef98726c18ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import platform\n",
    "\n",
    "# Configuration\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f5dd4ab8496b63",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44e57470c1d6bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "DATA_DIR = Path(\"data\")\n",
    "INPUT_FILENAME = DATA_DIR / \"PORTRAIT_last.csv\"\n",
    "OUTPUT_FILENAME = DATA_DIR / \"PORTRAIT_last_updated.csv\"\n",
    "\n",
    "# Column names\n",
    "RESPONDENT_ID = \"respondent_id\"\n",
    "USER_CODE = \"Código de usuario\"\n",
    "GENDER = (\n",
    "    \"¿Con qué género se identifica más usted? \"\n",
    "    \"(Selecciona la opción que más te identifique)\"\n",
    ")\n",
    "\n",
    "# Users to exclude\n",
    "USERS_TO_REMOVE = {\n",
    "    \"1XIH2\", \"B1Q2C\", \"KY12C\", \"QO12D\", \"S1HA2\",\n",
    "    \"XZ21K\", \"21WYJ\", \"B21DT\",\n",
    "}\n",
    "\n",
    "# Duplicate users to remove (user_code: respondent_id)\n",
    "DUPLICATES_TO_REMOVE = {\n",
    "    \"1H2GG\": \"118898041284\",\n",
    "    \"IC21Y\": \"118919025758\",\n",
    "    \"B2I1M\": \"118915917238\",\n",
    "    \"1Y2ZF\": \"118877646327\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc195b489d73151c",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4cd5349ab2a461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_column_index(header_row: pd.Series, target_value: str) -> int:\n",
    "    \"\"\"Find index of target_value in header_row.\n",
    "\n",
    "    Args:\n",
    "        header_row: Pandas Series containing column headers\n",
    "        target_value: String to find in header_row\n",
    "\n",
    "    Returns:\n",
    "        int: Index of the target value\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If target_value is not found in header_row\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return header_row.tolist().index(target_value)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(\n",
    "            f\"Header value '{target_value}' not found in DataFrame header.\\n\"\n",
    "            f\"Available headers: {header_row.tolist()}\"\n",
    "        ) from e\n",
    "\n",
    "def clean_user_code(df: pd.DataFrame, user_col_idx: int) -> None:\n",
    "    \"\"\"Clean and standardize user codes in the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        user_col_idx: Index of the user code column\n",
    "    \"\"\"\n",
    "    df.iloc[3:, user_col_idx] = (\n",
    "        df.iloc[3:, user_col_idx]\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .str.upper()\n",
    "    )\n",
    "\n",
    "def remove_duplicate_users(\n",
    "    df: pd.DataFrame,\n",
    "    user_col_idx: int,\n",
    "    dupes: Dict[str, str]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Remove duplicate users based on user code and respondent ID.\n",
    "\n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        user_col_idx: Index of the user code column\n",
    "        dupes: Dictionary mapping user codes to respondent IDs to remove\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with duplicates removed\n",
    "    \"\"\"\n",
    "    mask = ~(\n",
    "        (df.iloc[:, user_col_idx].isin(dupes.keys())) &\n",
    "        (df[df.columns[0]].astype(str).isin(dupes.values()))\n",
    "    )\n",
    "    return df[mask].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d694e2ffe16ee2",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee444d19160fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure data directory exists\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Read the raw data\n",
    "print(f\"Reading data from {INPUT_FILENAME}...\")\n",
    "df = pd.read_csv(INPUT_FILENAME, header=None)\n",
    "\n",
    "# Remove last 8 rows (typically metadata)\n",
    "df = df.iloc[:-8, :]\n",
    "\n",
    "# Add sequence numbers as first row\n",
    "seq_df = pd.DataFrame([range(1, df.shape[1] + 1)])\n",
    "df = pd.concat([seq_df, df], ignore_index=True)\n",
    "\n",
    "# Display initial data info\n",
    "print(f\"Initial data shape: {df.shape}\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c39705912b4e42f",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8d455c3390de63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find column indices\n",
    "try:\n",
    "    user_col_idx = find_column_index(df.iloc[1], USER_CODE)\n",
    "    gender_col_idx = find_column_index(df.iloc[1], GENDER)\n",
    "    print(f\"Found columns: user_code at index {user_col_idx}, gender at index {gender_col_idx}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error finding required columns: {e}\")\n",
    "    raise\n",
    "\n",
    "# Clean and standardize user codes\n",
    "clean_user_code(df, user_col_idx)\n",
    "\n",
    "# Remove duplicate users\n",
    "df = remove_duplicate_users(df, user_col_idx, DUPLICATES_TO_REMOVE)\n",
    "\n",
    "# Remove users in the exclusion list\n",
    "df = df[~df.iloc[:, user_col_idx].isin(USERS_TO_REMOVE)]\n",
    "\n",
    "# EXTRA CASES\n",
    "# Change usrername 02E1T to O2E1T\n",
    "df.iloc[3:, user_col_idx] = df.iloc[3:, user_col_idx].replace(\"02E1T\", \"O2E1T\")\n",
    "\n",
    "# Save processed data\n",
    "df.to_csv(OUTPUT_FILENAME, index=False, header=False)\n",
    "print(f\"Processed data saved to {OUTPUT_FILENAME}\")\n",
    "print(f\"Number of participants: {len(df) - 3}\")\n",
    "\n",
    "# Display the cleaned data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa299cdc916e6be0",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4abc1d93c03b7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example analysis: Basic statistics\n",
    "if len(df) > 3:  # Ensure we have data\n",
    "    # Get the data rows (skip first 3 header rows)\n",
    "    data_rows = df.iloc[3:]\n",
    "\n",
    "    # Example: Count by gender if gender column exists\n",
    "    if gender_col_idx is not None:\n",
    "        gender_counts = data_rows.iloc[:, gender_col_idx].value_counts()\n",
    "        print(\"Gender distribution:\")\n",
    "        print(gender_counts)\n",
    "\n",
    "        # Simple visualization\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        gender_counts.plot(kind='bar')\n",
    "        plt.title('Gender Distribution')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec75480b0919bce3",
   "metadata": {},
   "source": [
    "# Read updated csv and initialize needed variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf03a1c3ceb9984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the updated CSV file\n",
    "df = pd.read_csv(OUTPUT_FILENAME, header=None)\n",
    "header_row = df.iloc[0]\n",
    "subheader_row    = df.iloc[1]   # e.g. contains \"Durante las últimas dos semanas…\", “Código de usuario”, etc.\n",
    "subsubheader_row = df.iloc[2]   # e.g. contains \"Little interest…\", “Ninguna de las anteriores”, etc.\n",
    "user_col_index = find_column_index(subheader_row, \"Código de usuario\")\n",
    "sex_col_index = find_column_index(subheader_row, \"¿Con qué género se identifica más usted? (Selecciona la opción que más te identifique)\")\n",
    "\n",
    "# Define all test configurations\n",
    "TEST_CONFIG = {\n",
    "    \"PHQ\": {\n",
    "        \"header\": \"Durante las últimas dos semanas, ¿con qué frecuencia ha tenido molestias debido a los siguientes problemas?\",\n",
    "        \"end_marker\": \"Si ha marcado cualquiera de los problemas, ¿Qué tanta dificultad le han dado estos problemas para hacer su trabajo, encargarse de las tareas del hogar, o llevarse bien con otras personas?\",\n",
    "        \"end_marker_row\": \"subheader\",\n",
    "        \"end_adjustment\": -1,  # Adjust end index by -1 for PHQ\n",
    "        \"range\": (0, 3),\n",
    "        \"description\": \"Patient Health Questionnaire\"\n",
    "    },\n",
    "    \"BAI\": {\n",
    "        \"header\": \"En el cuestionario hay una lista de síntomas comunes de la ansiedad. Lea cada uno de los ítems atentamente, e indique cuanto le ha afectado en la última semana incluyendo hoy:\",\n",
    "        \"end_marker\": \"Con sudores, fríos o calientes.\",\n",
    "        \"end_marker_row\": \"subsubheader\",\n",
    "        \"range\": (0, 4),\n",
    "        \"description\": \"Beck Anxiety Inventory\"\n",
    "    },\n",
    "    \"OCI\": {\n",
    "        \"header\": \"Escoge la opción que mejor describe CUÁNTO malestar o molestia te ha producido esta experiencia durante el último mes.\",\n",
    "        \"end_marker\": \"Tener con frecuencia pensamientos repugnantes y que le cueste librarse de ellos.\",\n",
    "        \"end_marker_row\": \"subsubheader\",\n",
    "        \"range\": (0, 4),\n",
    "        \"description\": \"Obsessive-Compulsive Inventory\"\n",
    "    },\n",
    "    \"STAI\": {\n",
    "        \"header\": \"Lea cada frase y señale la opción que indique mejor cómo se siente en general, en la mayoría de las ocasiones. No hay respuestas buenas ni malas. No emplee demasiado tiempo en cada frase y conteste señalando la respuesta que mejor describa cómo se siente usted generalmente.\",\n",
    "        \"end_marker\": \"Cuando pienso sobre asuntos y preocupaciones actuales me pongo tenso y agitado.\",\n",
    "        \"end_marker_row\": \"subsubheader\",\n",
    "        \"reverse_items\": [0, 5, 6, 9, 12, 15, 18],  # 0-based item numbers\n",
    "        \"range\": (0, 3),\n",
    "        \"description\": \"State-Trait Anxiety Inventory\"\n",
    "    },\n",
    "    \"BFI\": {\n",
    "        \"header\": \"Por favor, valore cada afirmación del cuestionario en una escala del 1 al 5, donde 1 significa \\\"Muy en desacuerdo\\\" y 5 \\\"Muy de acuerdo\\\".\",\n",
    "        \"end_marker\": \"Es sofisticado en arte, música o literatura.\",\n",
    "        \"end_marker_row\": \"subsubheader\",\n",
    "        \"range\": (1, 5),\n",
    "        \"description\": \"Big Five Inventory\",\n",
    "        \"subscales\": {\n",
    "            \"Extraversion\": [1, 6, 11, 16, 21, 26, 31, 36],\n",
    "            \"Agreeableness\": [2, 7, 12, 17, 22, 27, 32, 37, 42],\n",
    "            \"Conscientiousness\": [3, 8, 13, 18, 23, 28, 33, 38, 43],\n",
    "            \"Neuroticism\": [4, 9, 14, 19, 24, 29, 34, 39],\n",
    "            \"Openness\": [5, 10, 15, 20, 25, 30, 35, 40, 41, 44]\n",
    "        },\n",
    "        \"reverse_scored_items\": {\n",
    "            \"Extraversion\": [6, 21, 31],\n",
    "            \"Agreeableness\": [2, 12, 27, 37],\n",
    "            \"Conscientiousness\": [8, 18, 23, 43],\n",
    "            \"Neuroticism\": [9, 24, 34],\n",
    "            \"Openness\": [35, 41]\n",
    "        }\n",
    "    },\n",
    "    \"ASSIST\": {\n",
    "        \"header\": \"A lo largo de la vida, ¿cuál de las siguientes sustancias ha consumido alguna vez? (solo que consumió sin receta médica)\",\n",
    "        \"end_header\": \"¿Alguna vez ha consumido alguna droga por vía inyectada? (solo las que consumió sin receta médica)\",\n",
    "        \"first_sub\": \"Ninguna de las anteriores\",\n",
    "        \"last_sub\": \"Response\",\n",
    "        \"allowed_codes\": {\n",
    "            2: {0, 2, 3, 4, 6},\n",
    "            3: {0, 3, 4, 5, 6},\n",
    "            4: {0, 4, 5, 6, 7},\n",
    "            5: {0, 5, 6, 7, 8},\n",
    "            6: {0, 6, 3},\n",
    "            7: {0, 6, 3}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "def find_test_indices(header_lookup, test_config):\n",
    "    \"\"\"Find start and end indices for a test section.\"\"\"\n",
    "    start_index = find_column_index(header_lookup, test_config[\"header\"])\n",
    "\n",
    "    # Determine which row to find the end marker in\n",
    "    if test_config.get(\"end_marker_row\") == \"subsubheader\":\n",
    "        end_row = subsubheader_row\n",
    "    else:\n",
    "        end_row = subheader_row\n",
    "\n",
    "    end_index = find_column_index(end_row, test_config[\"end_marker\"])\n",
    "\n",
    "    # Apply any adjustments to the end index\n",
    "    if \"end_adjustment\" in test_config:\n",
    "        end_index += test_config[\"end_adjustment\"]\n",
    "\n",
    "    return start_index, end_index\n",
    "\n",
    "# Find all test indices\n",
    "test_indices = {}\n",
    "for test_name, config in TEST_CONFIG.items():\n",
    "    if test_name == \"ASSIST\":\n",
    "        # Special handling for ASSIST\n",
    "        assist_start_index = find_column_index(subheader_row, config[\"header\"])\n",
    "        assist_end_index = find_column_index(subheader_row, config[\"end_header\"])\n",
    "        assist_first_sub_idx = find_column_index(subsubheader_row, config[\"first_sub\"])\n",
    "        assist_last_sub_idx = find_column_index(subsubheader_row, config[\"last_sub\"])\n",
    "\n",
    "        test_indices.update({\n",
    "            \"assist_start_index\": assist_start_index,\n",
    "            \"assist_end_index\": assist_end_index,\n",
    "            \"assist_first_sub_idx\": assist_first_sub_idx,\n",
    "            \"assist_last_sub_idx\": assist_last_sub_idx\n",
    "        })\n",
    "\n",
    "        # Additional ASSIST-specific variables\n",
    "        first_substance_index = assist_start_index + 1\n",
    "        base_cols = list(range(first_substance_index, first_substance_index + 9))\n",
    "        sub_names = df.iloc[2, base_cols].tolist()\n",
    "        assist_allowed = config[\"allowed_codes\"]\n",
    "    else:\n",
    "        # Standard test processing\n",
    "        try:\n",
    "            start, end = find_test_indices(subheader_row, config)\n",
    "            test_indices[f\"{test_name.lower()}_start_index\"] = start\n",
    "            test_indices[f\"{test_name.lower()}_end_index\"] = end\n",
    "            print(f\"Found {config['description']} ({test_name}) at columns {start}-{end}\")\n",
    "        except ValueError as e:\n",
    "            print(f\"Warning: Could not find {test_name} test: {e}\")\n",
    "\n",
    "# Add standard column indices\n",
    "test_indices.update({\n",
    "    \"user_col_index\": find_column_index(subheader_row, \"Código de usuario\"),\n",
    "    \"sex_col_index\": find_column_index(subheader_row,\n",
    "        \"¿Con qué género se identifica más usted? (Selecciona la opción que más te identifique)\")\n",
    "})\n",
    "\n",
    "# Make all indices available as variables in the notebook\n",
    "locals().update(test_indices)\n",
    "\n",
    "# Generate BFI subscales with absolute column indices\n",
    "if 'bfi_start_index' in test_indices:\n",
    "    bfi_subscales = {\n",
    "        trait: [test_indices['bfi_start_index'] + (q - 1) for q in questions]\n",
    "        for trait, questions in TEST_CONFIG[\"BFI\"][\"subscales\"].items()\n",
    "    }\n",
    "    reverse_scored_items = TEST_CONFIG[\"BFI\"][\"reverse_scored_items\"]\n",
    "\n",
    "#  STAI reverse items (0-based)\n",
    "stai_items_to_reverse = TEST_CONFIG[\"STAI\"][\"reverse_items\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bad0f09a1ba7451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_description(test_name, test_config, start_idx, end_idx):\n",
    "    \"\"\"Generate a detailed description of the test validation.\"\"\"\n",
    "    description = f\"# Test {test_name}\\n\"\n",
    "    description += f\"- Description: {test_config.get('description', 'No description available')}\\n\"\n",
    "    description += f\"- Columns: {start_idx} to {end_idx}\\n\"\n",
    "    description += f\"- Valid range: {test_config.get('range', (0, 3))}\\n\"\n",
    "    return description\n",
    "\n",
    "def validate_test_responses(df, test_name, start_idx, end_idx, valid_range, start_row=3):\n",
    "    \"\"\"\n",
    "    Validate that all responses for a test fall within the specified range.\n",
    "    Returns: tuple of (passed, issues, detailed_report)\n",
    "    \"\"\"\n",
    "    min_val, max_val = valid_range\n",
    "    issues = []\n",
    "    detailed_report = []\n",
    "    passed = True\n",
    "\n",
    "    # Add test header to detailed report\n",
    "    detailed_report.append(f\"# Test {test_name}\")\n",
    "\n",
    "    # Check if indices are valid\n",
    "    if start_idx >= len(df.columns) or end_idx >= len(df.columns):\n",
    "        error_msg = f\"  - Error: Column indices out of bounds (max: {len(df.columns)-1})\"\n",
    "        issues.append(error_msg)\n",
    "        detailed_report.append(error_msg)\n",
    "        return False, issues, detailed_report\n",
    "\n",
    "    # Add column range info\n",
    "    detailed_report.append(f\"- Validating columns {start_idx} to {end_idx} (range: {min_val}-{max_val})\")\n",
    "\n",
    "    # Get the range of columns to check\n",
    "    cols_to_test = list(range(start_idx, end_idx + 1))\n",
    "    valid_count = 0\n",
    "    total_cells = 0\n",
    "\n",
    "    for row_idx in range(start_row, len(df)):\n",
    "        for col_idx in cols_to_test:\n",
    "            total_cells += 1\n",
    "            header_val = df.iloc[0, col_idx] if col_idx < len(df.iloc[0]) else \"N/A\"\n",
    "            cell = df.iloc[row_idx, col_idx]\n",
    "\n",
    "            # Check for missing values\n",
    "            if pd.isna(cell):\n",
    "                issue = f\"  - Row {row_idx+1}, Column {col_idx+1} (header: {header_val}) is empty\"\n",
    "                issues.append(issue)\n",
    "                detailed_report.append(issue)\n",
    "                passed = False\n",
    "                continue\n",
    "\n",
    "            # Check if value is numeric and in range\n",
    "            try:\n",
    "                value = float(cell)\n",
    "                if not (min_val <= value <= max_val):\n",
    "                    issue = f\"  - Row {row_idx+1}, Column {col_idx+1} (header: {header_val}): Value {value} out of range\"\n",
    "                    issues.append(issue)\n",
    "                    detailed_report.append(issue)\n",
    "                    passed = False\n",
    "                else:\n",
    "                    valid_count += 1\n",
    "            except (ValueError, TypeError):\n",
    "                issue = f\"  - Row {row_idx+1}, Column {col_idx+1} (header: {header_val}): Non-numeric value: {cell}\"\n",
    "                issues.append(issue)\n",
    "                detailed_report.append(issue)\n",
    "                passed = False\n",
    "\n",
    "    # Add summary to detailed report\n",
    "    if passed:\n",
    "        detailed_report.append(f\"\\n✓ All {valid_count} values are valid\")\n",
    "    else:\n",
    "        detailed_report.append(f\"\\n✗ Found {len(issues)} issues in {total_cells} cells\")\n",
    "\n",
    "    return passed, issues, detailed_report\n",
    "\n",
    "def validate_all_tests(df, test_configs, test_indices):\n",
    "    \"\"\"Validate all tests and return detailed reports.\"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for test_name, config in test_configs.items():\n",
    "        if test_name == \"ASSIST\":\n",
    "            continue  # Skip ASSIST as it has different validation rules\n",
    "\n",
    "        test_key = test_name.lower()\n",
    "        start_idx = test_indices.get(f\"{test_key}_start_index\")\n",
    "        end_idx = test_indices.get(f\"{test_key}_end_index\")\n",
    "\n",
    "        if start_idx is None or end_idx is None:\n",
    "            print(f\"Skipping {test_name}: Missing indices\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n=== Validating {test_name} ===\")\n",
    "        valid_range = config.get(\"range\", (0, 3))\n",
    "\n",
    "        # Get test description\n",
    "        test_desc = get_test_description(test_name, config, start_idx, end_idx)\n",
    "        print(test_desc)\n",
    "\n",
    "        # Run validation\n",
    "        passed, issues, detailed_report = validate_test_responses(\n",
    "            df, test_name, start_idx, end_idx, valid_range\n",
    "        )\n",
    "\n",
    "        # Print detailed report\n",
    "        print(\"\\n\".join(detailed_report))\n",
    "\n",
    "        # Store results\n",
    "        results[test_name] = {\n",
    "            \"passed\": passed,\n",
    "            \"issues\": issues,\n",
    "            \"num_issues\": len(issues),\n",
    "            \"columns\": f\"{start_idx}-{end_idx}\",\n",
    "            \"valid_range\": valid_range,\n",
    "            \"report\": detailed_report\n",
    "        }\n",
    "\n",
    "        status = \"✓ PASSED\" if passed else f\"✗ FAILED ({len(issues)} issues)\"\n",
    "        print(f\"\\n{status}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run the validation\n",
    "print(\"=== Starting Validation ===\\n\")\n",
    "validation_results = validate_all_tests(df, TEST_CONFIG, test_indices)\n",
    "\n",
    "# Print final summary\n",
    "print(\"\\n=== Final Validation Summary ===\")\n",
    "print(\"PASSED TESTS:\")\n",
    "passed_tests = [name for name, result in validation_results.items() if result[\"passed\"]]\n",
    "if passed_tests:\n",
    "    for name in passed_tests:\n",
    "        print(f\"✓ {name} (columns {validation_results[name]['columns']})\")\n",
    "else:\n",
    "    print(\"No tests passed validation.\")\n",
    "\n",
    "print(\"\\nFAILED TESTS:\")\n",
    "failed_tests = [name for name, result in validation_results.items() if not result[\"passed\"]]\n",
    "if failed_tests:\n",
    "    for name in failed_tests:\n",
    "        result = validation_results[name]\n",
    "        print(f\"✗ {name} (columns {result['columns']}): {result['num_issues']} issues\")\n",
    "else:\n",
    "    print(\"All tests passed validation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c87d678bcc53a1",
   "metadata": {},
   "source": [
    "# TEST ASSIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f339fcf51d578f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range(3, df.shape[0]):\n",
    "    # Special case if \"Ninguna de las anteriores\"\n",
    "    if pd.notna(df.iat[r, assist_first_sub_idx]) and int(df.iat[r, assist_first_sub_idx]) == 0:\n",
    "        if not df.iloc[r][first_substance_index:assist_end_index].isna().all():\n",
    "            subset = df.iloc[r][first_substance_index:assist_end_index]\n",
    "            not_na = subset[~subset.isna()]\n",
    "            raise ValueError(f\"Not all values of row {r} between columns {first_substance_index} and {assist_end_index} are NaN: {not_na.to_dict()}\")\n",
    "        continue\n",
    "    for c in range(assist_start_index, assist_start_index + 9):\n",
    "        val = df.iat[r, c]\n",
    "        header = df.iat[2, c]\n",
    "        if pd.notna(val):\n",
    "            if header != \"Otro (especifique)\":\n",
    "                # If the “next” question is 0, zero out the three follow-ups\n",
    "                if int(df.iat[r, c + 9]) == 0:\n",
    "                    df.iat[r, c + 18] = df.iat[r, c + 27] = df.iat[r, c + 36] = 0\n",
    "                # Checking all the values for each specific substance (i.e. every next 9 columns)\n",
    "                for qnum, allowed_vals in assist_allowed.items():\n",
    "                    sc = c + 9 * (qnum - 1)  # substance column\n",
    "                    resp = int(df.iat[r, sc])\n",
    "                    if resp in allowed_vals:\n",
    "                        continue\n",
    "                    else:\n",
    "                        raise ValueError(\n",
    "                            f\"In Question {qnum}, Column {sc} found: {resp}\\n\"\n",
    "                            f\"assist_allowed Values are: {allowed_vals}\"\n",
    "                        )\n",
    "# Skip value validation as per the user's request\n",
    "print(\"Passed ASSIST value validation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148cf419d958a132",
   "metadata": {},
   "source": [
    "# Results ASSIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5509b041353322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare to collect per-user dicts\n",
    "results = []\n",
    "for r in range(3, df.shape[0]):\n",
    "    username = df.iat[r, user_col_index]\n",
    "    rec = {\"username\": username}\n",
    "\n",
    "    for c, name in zip(base_cols, sub_names):\n",
    "        offsets = [9*i for i in range(1,7)]       # Q2–Q7\n",
    "        if name.startswith(\"Tabaco\"):\n",
    "            offsets.remove(36)                    # drop Q5\n",
    "        total = sum(int(df.iat[r, c+off])       # NaN→skip\n",
    "                    for off in offsets\n",
    "                    if pd.notna(df.iat[r, c+off]))\n",
    "        rec[name] = total\n",
    "\n",
    "    results.append(rec)\n",
    "assist_scores_df = pd.DataFrame(results)\n",
    "\n",
    "low_max = {\n",
    "  \"Tabaco (cigarrillos, tabaco de mascar, puros, etc.)\": 3,\n",
    "  \"Alcohol\": 10,\n",
    "}\n",
    "moderate_max = 26\n",
    "\n",
    "\n",
    "for col in assist_scores_df.columns:\n",
    "    if col == \"username\": continue\n",
    "    lo   = low_max.get(col, 3)\n",
    "    sc   = assist_scores_df[col]\n",
    "    masks = [\n",
    "      sc <= lo,\n",
    "      sc.between(lo+1, moderate_max),\n",
    "      sc >= (moderate_max+1),\n",
    "    ]\n",
    "    labels = [\n",
    "      \"No requiere intervención\",\n",
    "      \"Recibir intervención breve\",\n",
    "      \"Tratamiento más intensivo\",\n",
    "    ]\n",
    "    #assist_scores_df[f\"{col}_risk\"] = np.select(masks, labels, default=np.nan)\n",
    "    assist_scores_df[f\"{col}_risk\"] = np.select(masks, labels, default=\"Unknown\")\n",
    "\n",
    "# 3) inspect\n",
    "assist_scores_df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d693e099b168ebe",
   "metadata": {},
   "source": [
    "# TOTAL RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dfe7d384f6cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_test_scores(row, start_idx, end_idx, test_name):\n",
    "    \"\"\"Helper function to calculate test scores with error handling.\"\"\"\n",
    "    try:\n",
    "        scores = row[start_idx:end_idx + 1].astype(float)\n",
    "        return int(scores.sum())\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error processing {test_name} responses for user '{row[user_col_index]}': {e}\")\n",
    "\n",
    "def process_stai_scores(row, start_idx, end_idx, items_to_reverse, sex_col_index):\n",
    "    \"\"\"Process STAI scores with reverse scoring and classification.\"\"\"\n",
    "    try:\n",
    "        scores = row[start_idx:end_idx + 1].astype(float).copy()\n",
    "\n",
    "        # Apply reverse scoring\n",
    "        for item in items_to_reverse:\n",
    "            col_idx = start_idx + item\n",
    "            if not pd.isna(row[col_idx]):\n",
    "                scores.iloc[item] = 3 - int(scores.iloc[item])\n",
    "\n",
    "        total = int(scores.sum())\n",
    "        sex = row[sex_col_index]\n",
    "\n",
    "        # Classify based on gender\n",
    "        if sex == \"3\":\n",
    "            classification = \"Binary\"\n",
    "        elif (sex == \"2\" and total >= 29) or (sex == \"1\" and total >= 37):\n",
    "            classification = \"Severe\"\n",
    "        else:\n",
    "            classification = \"Low/Normal\"\n",
    "\n",
    "        return total, classification\n",
    "\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error processing STAI responses for user '{row[user_col_index]}': {e}\")\n",
    "\n",
    "def process_bfi_scores(row, start_idx, subscales, reverse_items):\n",
    "    \"\"\"Process BFI scores with reverse scoring.\"\"\"\n",
    "    try:\n",
    "        bfi_scores = {}\n",
    "        for subscale, cols in subscales.items():\n",
    "            scores = []\n",
    "            for col in cols:\n",
    "                try:\n",
    "                    value = float(row[col])\n",
    "                    # Reverse score if needed\n",
    "                    if col - start_idx + 1 in reverse_items.get(subscale, []):\n",
    "                        value = 6 - value\n",
    "                    scores.append(value)\n",
    "                except ValueError:\n",
    "                    raise ValueError(f\"Invalid BFI value in column {col}: {row[col]}\")\n",
    "            bfi_scores[subscale] = round(sum(scores) / len(scores), 2)\n",
    "        return bfi_scores\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error processing BFI responses: {e}\")\n",
    "\n",
    "def classify_phq(score):\n",
    "    \"\"\"Classify PHQ score into depression severity levels.\"\"\"\n",
    "    if score < 5: return \"Low\"\n",
    "    if score < 10: return \"Mild depression\"\n",
    "    if score < 15: return \"Moderate depression\"\n",
    "    if score < 20: return \"Moderately severe depression\"\n",
    "    return \"Severe depression\"\n",
    "\n",
    "def classify_bai(score):\n",
    "    \"\"\"Classify BAI score into anxiety levels.\"\"\"\n",
    "    if score <= 21: return \"Low anxiety\"\n",
    "    if score <= 35: return \"Moderate anxiety\"\n",
    "    return \"Potentially concerning levels of anxiety\"\n",
    "\n",
    "def classify_oci(score):\n",
    "    \"\"\"Classify OCI score for OCD indication.\"\"\"\n",
    "    return \"Presence of OCD\" if score > 21 else \"No sign of OCD\"\n",
    "\n",
    "# Merge dataframes\n",
    "df = df.merge(\n",
    "    assist_scores_df,\n",
    "    left_on=df.columns[user_col_index],\n",
    "    right_on=\"username\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Get substance names dynamically\n",
    "sub_names = [c for c in assist_scores_df.columns\n",
    "            if c != \"username\" and not c.endswith((\"_risk\", \"_classification\"))]\n",
    "\n",
    "print(\"START\")\n",
    "# Process each user's responses\n",
    "for idx in range(3, len(df)):\n",
    "    row = df.iloc[idx]\n",
    "    username = row[user_col_index]\n",
    "    try:\n",
    "        # Calculate test scores\n",
    "        phq_total = calculate_test_scores(row, phq_start_index, phq_end_index, \"PHQ\")\n",
    "        bai_total = calculate_test_scores(row, bai_start_index, bai_end_index, \"BAI\")\n",
    "        oci_total = calculate_test_scores(row, oci_start_index, oci_end_index, \"OCI\")\n",
    "        stai_total, stai_classification = process_stai_scores(\n",
    "            row, stai_start_index, stai_end_index, stai_items_to_reverse, sex_col_index\n",
    "        )\n",
    "\n",
    "        # Process BFI scores\n",
    "        bfi_scores = process_bfi_scores(row, bfi_start_index, bfi_subscales, reverse_scored_items)\n",
    "\n",
    "        # Classify scores\n",
    "        classifications = {\n",
    "            \"phq\": (phq_total, classify_phq(phq_total)),\n",
    "            \"bai\": (bai_total, classify_bai(bai_total)),\n",
    "            \"oci\": (oci_total, classify_oci(oci_total)),\n",
    "            \"stai\": (stai_total, stai_classification)\n",
    "        }\n",
    "\n",
    "        # Update dataframe with results\n",
    "        for prefix, (total, classification) in classifications.items():\n",
    "            df.at[idx, f\"{prefix}_total\"] = total\n",
    "            df.at[idx, f\"{prefix}_classification\"] = classification\n",
    "\n",
    "        # Add BFI subscale scores\n",
    "        for subscale, score in bfi_scores.items():\n",
    "            df.at[idx, f\"BFI_{subscale}\"] = score\n",
    "\n",
    "        # Print report\n",
    "        report = (\n",
    "            f\"{username}: PHQ Total = {phq_total} ({classifications['phq'][1]}), \"\n",
    "            f\"OCI Total = {oci_total} ({classifications['oci'][1]}), \"\n",
    "            f\"BAI Total = {bai_total} ({classifications['bai'][1]}), \"\n",
    "            f\"STAI Total = {stai_total} ({stai_classification}), \"\n",
    "            f\"BFI Scores = {bfi_scores}\"\n",
    "        )\n",
    "        print(report)\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Error processing {username}: {str(e)}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6585b7b59ae7b5a0",
   "metadata": {},
   "source": [
    "# Binary classes for BFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ab0a34a9afa4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_bfi_scores(df, bfi_subscales, median_cutoffs=None):\n",
    "    \"\"\"\n",
    "    Classify BFI scores as Low/High based on median cutoffs.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame containing BFI scores\n",
    "        bfi_subscales: Dictionary of BFI subscales and their column indices\n",
    "        median_cutoffs: Optional dictionary of custom median cutoffs. If None, uses default values.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with added classification columns\n",
    "    \"\"\"\n",
    "    # https://www.researchgate.net/figure/Descriptive-statistics-for-the-variables-included-in-Study-3_tbl4_362005430\n",
    "    # Define median cutoffs (or use defaults)\n",
    "    # Set default median cutoffs if not provided\n",
    "    if median_cutoffs is None:\n",
    "        median_cutoffs = {\n",
    "            \"Extraversion\": 3.42,\n",
    "            \"Agreeableness\": 3.87,\n",
    "            \"Conscientiousness\": 3.40,\n",
    "            \"Neuroticism\": 3.13,\n",
    "            \"Openness\": 2.98\n",
    "        }\n",
    "\n",
    "    # Create classification columns\n",
    "    for subscale in bfi_subscales:\n",
    "        col_name = f\"BFI_{subscale}\"\n",
    "        df[f\"{col_name}_classification\"] = df[col_name].apply(\n",
    "            lambda x: \"Low\" if x < median_cutoffs[subscale] else \"High\"\n",
    "        )\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# df = classify_bfi_scores(df, bfi_subscales)\n",
    "\n",
    "# Apply the classification\n",
    "df = classify_bfi_scores(df, bfi_subscales)\n",
    "\n",
    "# Optional: Print results\n",
    "for idx, row in df[3:].iterrows():\n",
    "    username = row[user_col_index]\n",
    "    bfi_scores = {subscale: row[f\"BFI_{subscale}\"] for subscale in bfi_subscales}\n",
    "    bfi_class = {subscale: row[f\"BFI_{subscale}_classification\"] for subscale in bfi_subscales}\n",
    "    print(f\"{username}: BFI Scores = {bfi_scores}, BFI Class = {bfi_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e2eb2d77498bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df = df[3:]\n",
    "\n",
    "# Define output files\n",
    "output_files = {\n",
    "    'excel': 'results_surveyMonkey_Processed.xlsx',\n",
    "    'csv': 'results_surveyMonkey_Processed.csv'\n",
    "}\n",
    "\n",
    "# Get responses and create results DataFrame\n",
    "responses_df = df[3:]\n",
    "results_cols = {\n",
    "    'username': responses_df.iloc[:, user_col_index],\n",
    "    'gender': responses_df.iloc[:, sex_col_index],\n",
    "    **{col: responses_df[col] for col in [\n",
    "        'phq_total', 'phq_classification',\n",
    "        'oci_total', 'oci_classification',\n",
    "        'bai_total', 'bai_classification',\n",
    "        'stai_total', 'stai_classification'\n",
    "    ]}\n",
    "}\n",
    "# Add any additional assist columns here if needed (example):\n",
    "# \"assist_column\": responses_df[\"assist_column_name\"]\n",
    "\n",
    "results_df = pd.DataFrame(results_cols)\n",
    "\n",
    "# Add BFI columns\n",
    "for sub in bfi_subscales:\n",
    "    results_df[[f'BFI_{sub}', f'BFI_{sub}_classification']] = responses_df[[f'BFI_{sub}', f'BFI_{sub}_classification']]\n",
    "\n",
    "\n",
    "# Merge with assist scores and export\n",
    "results_df = results_df.merge(assist_scores_df, on='username', how='left')\n",
    "results_df.to_excel(output_files['excel'], index=False)\n",
    "results_df.to_csv(output_files['csv'], index=False)\n",
    "\n",
    "# Copy to network location\n",
    "if platform.system() == 'Windows':\n",
    "    dest_path = r'W:\\Portrait\\SVM\\data\\results_surveyMonkey_Processed.csv'\n",
    "else:\n",
    "    dest_path = \"/Volumes/mgialou/Portrait/SVM/data/results_surveyMonkey_Processed.csv\"\n",
    "\n",
    "\n",
    "# Copy the file\n",
    "#shutil.copy2(\"results_surveyMonkey_Processed.csv\", CSV_PATH)\n",
    "\n",
    "print(f\"Results exported to {output_files['excel']} and {output_files['csv']}\")\n",
    "print(f\"CSV file would be copied to: {dest_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711e1d6fee73627e",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bfcc44cc259e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: use DataFrame.filter with a regex\n",
    "# Option B: single-filter regex\n",
    "# Option C: boolean mask\n",
    "mask = responses_df.columns.str.startswith('BFI') | responses_df.columns.str.startswith('username')\n",
    "responses_df.loc[:, mask].head(50)\n",
    "df = responses_df\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1293bf08068faf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_codes = df.loc[3:, sex_col_index].dropna().astype(int)\n",
    "gender_map = {1: \"Female\", 2: \"Male\", 3: \"Non-binary\"}\n",
    "genders = sex_codes.map(gender_map)\n",
    "\n",
    "order = [\"Female\", \"Male\", \"Non-binary\"]\n",
    "counts = genders.value_counts().reindex(order, fill_value=0)\n",
    "print(\"Counts of gender: \", counts)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(counts.index, counts.values, edgecolor='black')\n",
    "plt.title(\"Gender Distribution of Respondents\")\n",
    "plt.ylabel(\"Number of Users\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b3e836e1a630b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure these columns exist (you can do this before the loop)\n",
    "new_cols = [\n",
    "  \"phq_total\",\"phq_classification\",\n",
    "  \"oci_total\",\"oci_classification\",\n",
    "  \"bai_total\",\"bai_classification\",\n",
    "  \"stai_total\",\"stai_classification\"\n",
    "] + [f\"BFI_{sub}\" for sub in bfi_subscales]\n",
    "# plus all ASSIST score and risk columns are already in df from the merge\n",
    "# Numeric totals\n",
    "\n",
    "# assemble totals into one DataFrame\n",
    "totals = df.loc[3:, [f for f in ['phq_total','bai_total','oci_total','stai_total']]].astype(int)\n",
    "print(totals)\n",
    "plt.figure(figsize=(10,6))\n",
    "for i, col in enumerate(totals.columns, 1):\n",
    "    plt.subplot(2,2,i)\n",
    "    plt.hist(totals[col], bins=12, edgecolor='black')\n",
    "    plt.title(col.replace('_',' ').upper())\n",
    "    plt.xlabel('Score')\n",
    "    plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b5dbcc499d8844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of your classification columns and plot titles\n",
    "class_cols = [\n",
    "    'phq_classification',\n",
    "    'bai_classification',\n",
    "    'oci_classification',\n",
    "    'stai_classification'\n",
    "]\n",
    "titles = [\n",
    "    'PHQ-9 Depression Severity',\n",
    "    'BAI Anxiety Level',\n",
    "    'OCI-R OCD Classification',\n",
    "    'STAI Anxiety Classification'\n",
    "]\n",
    "\n",
    "# Make the 2×2 plot\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, col, title in zip(axes, class_cols, titles):\n",
    "    # count each category\n",
    "    counts = df.loc[3:, col].value_counts().sort_index()\n",
    "    ax.bar(counts.index, counts.values, edgecolor='black')\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel('Number of Users')\n",
    "    ax.tick_params(axis='x', rotation=45, labelsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171db37545c3d080",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.boxplot([totals[c] for c in totals.columns], tick_labels=[c.upper() for c in totals.columns])\n",
    "plt.title(\"Distribution of Psychometric Assesment Scores\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87cfbc97c5f96ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub_names = ['Tabaco (cigarrillos, tabaco de mascar, puros, etc.)', 'Bebidas alcohólicas (cerveza, vinos, licores, etc.)']\n",
    "# reshape into long form\n",
    "assist_long = assist_scores_df.melt(id_vars='username',\n",
    "    value_vars=sub_names,\n",
    "    var_name='sustancia', value_name='score'\n",
    ").merge(\n",
    "    assist_scores_df.melt(id_vars='username',\n",
    "        value_vars=[f\"{s}_risk\" for s in sub_names],\n",
    "        var_name='tmp', value_name='risk'\n",
    "    ).assign(sustancia=lambda d: d['tmp'].str.replace('_risk',''))[['username','sustancia','risk']],\n",
    "    on=['username','sustancia']\n",
    ")\n",
    "\n",
    "# Filter out individuals with a score of 0 on the sustancias\n",
    "assist_long_filtered = assist_long[assist_long['score'] > 0]\n",
    "\n",
    "# count\n",
    "#counts = assist_long.groupby(['sustancia','risk']).size().unstack(fill_value=0)\n",
    "counts = assist_long_filtered.groupby(['sustancia','risk']).size().unstack(fill_value=0)\n",
    "\n",
    "# copia y acorta solo el primer término de cada etiqueta\n",
    "counts_short = counts.copy()\n",
    "counts_short.index = counts_short.index.str.split().str[0]\n",
    "\n",
    "# ya con índices cortos\n",
    "ax = counts_short.plot(\n",
    "    kind='bar',\n",
    "    stacked=True,\n",
    "    figsize=(10,6)\n",
    ")\n",
    "plt.title(\"Distribución de categorías de riesgo ASSIST por sustancia\")\n",
    "ax.legend(title=\"Riesgo\", bbox_to_anchor=(1,1))\n",
    "\n",
    "\n",
    "counts.plot(kind='bar', stacked=True, figsize=(10,6))\n",
    "plt.ylabel(\"Número de usuarios\")\n",
    "plt.title(\"Distribución de categorías de riesgo ASSIST por sustancia\")\n",
    "plt.legend(title=\"Riesgo\", bbox_to_anchor=(1,1))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda6c69ca3c32af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming you've merged bfi subscale columns (Extraversion, Agreeableness, …) into df\n",
    "bfi_cols = [\"BFI_Extraversion\",\"BFI_Agreeableness\",\"BFI_Conscientiousness\",\n",
    "            \"BFI_Neuroticism\",\"BFI_Openness\"]\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.boxplot(\n",
    "    [df.loc[3:, trait].astype(float) for trait in bfi_cols],\n",
    "    tick_labels=bfi_cols,\n",
    "    notch=True\n",
    ")\n",
    "plt.xticks(rotation=15)\n",
    "plt.ylabel(\"Mean Score\")\n",
    "plt.title(\"BFI Subscale Distributions\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0a5f9124ab4fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect a numeric matrix\n",
    "num_cols = [\"phq_total\",\"bai_total\",\"oci_total\",\"stai_total\"] + bfi_cols\n",
    "mat = df.loc[3:, num_cols].astype(float).corr()\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "im = plt.imshow(mat, aspect=\"auto\")\n",
    "plt.colorbar(im)\n",
    "plt.xticks(range(len(num_cols)), num_cols, rotation=45, ha=\"right\")\n",
    "plt.yticks(range(len(num_cols)), num_cols)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "# annotate the cells\n",
    "for i in range(len(num_cols)):\n",
    "    for j in range(len(num_cols)):\n",
    "        plt.text(j, i, f\"{mat.iat[i,j]:.2f}\", ha=\"center\", va=\"center\", fontsize=8, color=\"white\" if abs(mat.iat[i,j])>0.5 else \"black\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630fea8adec4a050",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
