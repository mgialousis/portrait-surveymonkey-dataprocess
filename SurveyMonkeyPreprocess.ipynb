{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "38a1e2f83b14a340"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import openpyxl\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "8efc76d3bbadb52b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Functions",
   "id": "2816f37a46fcb0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def find_column_index(hrow, target_value):\n",
    "    \"\"\"\n",
    "    Finds the index of target_value in the header_row.\n",
    "    Raises a ValueError if the target is not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return hrow.tolist().index(target_value)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"Header value '{target_value}' was not found in the DataFrame header.\")"
   ],
   "id": "a92a38a94210e185",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Read csv with all response, create new csv with appended header",
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "filename = \"data/\" + \"PORTRAIT_last\"\n",
    "filename_updated = filename + \"_updated\"\n",
    "# 1. Read the CSV file without any header\n",
    "df = pd.read_csv(filename + \".csv\", header=None)\n",
    "\n",
    "# Remove the last 8 rows\n",
    "df = df.iloc[:-8, :]\n",
    "\n",
    "# 2. Build the sequence as a 1-row DataFrame\n",
    "seq_df = pd.DataFrame([range(1, df.shape[1] + 1)])\n",
    "\n",
    "# 3. To PREPEND at the top:\n",
    "df_appended = pd.concat([seq_df, df], ignore_index=True)\n",
    "\n",
    "# Remove the row with Código de usuario = 1Y2ZF and género = 1\n",
    "user_col_index = find_column_index(df_appended.iloc[1], \"Código de usuario\")\n",
    "sex_col_index = find_column_index(df_appended.iloc[1], \"¿Con qué género se identifica más usted? (Selecciona la opción que más te identifique)\")\n",
    "df_appended = df_appended[~((df_appended.iloc[:, user_col_index] == \"1Y2ZF\") & (df_appended.iloc[:, sex_col_index] == \"1\"))]\n",
    "\n",
    "# Save the result to a new CSV file. You can change the file name accordingly.\n",
    "df_appended.to_csv(filename_updated + \".csv\", index=False, header=False)\n",
    "\n",
    "print(\"The CSV file has been successfully updated with a new initial row.\", filename_updated)"
   ],
   "id": "142aeedba18c8bab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Read updated csv and initialize needed variables",
   "id": "a97a24a6b584275c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the updated CSV file\n",
    "df = pd.read_csv(filename_updated + \".csv\", header=None)\n",
    "header_row = df.iloc[0]\n",
    "subheader_row    = df.iloc[1]   # e.g. contains \"Durante las últimas dos semanas…\", “Código de usuario”, etc.\n",
    "subsubheader_row = df.iloc[2]   # e.g. contains \"Little interest…\", “Ninguna de las anteriores”, etc.\n",
    "user_col_index = find_column_index(subheader_row, \"Código de usuario\")\n",
    "sex_col_index = find_column_index(subheader_row, \"¿Con qué género se identifica más usted? (Selecciona la opción que más te identifique)\")\n",
    "\n",
    "PHQ_HEADER = (\n",
    "  \"Durante las últimas dos semanas, ¿con qué frecuencia ha tenido molestias \"\n",
    "  \"debido a los siguientes problemas?\"\n",
    ")\n",
    "PHQ_LAST = (\n",
    "  \"Si ha marcado cualquiera de los problemas, ¿Qué tanta dificultad le han \"\n",
    "  \"dado estos problemas para hacer su trabajo, encargarse de las tareas \"\n",
    "  \"del hogar, o llevarse bien con otras personas?\"\n",
    ")\n",
    "phq_start_index = find_column_index(subheader_row, PHQ_HEADER)\n",
    "phq_end_index   = find_column_index(subheader_row, PHQ_LAST)\n",
    "\n",
    "BAI_HEADER      = (\n",
    "  \"En el cuestionario hay una lista de síntomas comunes de la ansiedad. Lea \"\n",
    "  \"cada uno de los ítems atentamente, e indique cuanto le ha afectado en la \"\n",
    "  \"última semana incluyendo hoy:\"\n",
    ")\n",
    "BAI_LAST_SUB    = \"Con sudores, fríos o calientes.\"\n",
    "bai_start_index = find_column_index(subheader_row, BAI_HEADER)\n",
    "bai_end_index   = find_column_index(subsubheader_row, BAI_LAST_SUB)\n",
    "\n",
    "OCI_HEADER      = (\n",
    "  \"Escoge la opción que mejor describe CUÁNTO malestar o molestia te ha \"\n",
    "  \"producido esta experiencia durante el último mes.\"\n",
    ")\n",
    "OCI_LAST_SUB    = (\n",
    "  \"Tener con frecuencia pensamientos repugnantes y que le cueste librarse de ellos.\"\n",
    ")\n",
    "oci_start_index = find_column_index(subheader_row, OCI_HEADER)\n",
    "oci_end_index   = find_column_index(subsubheader_row, OCI_LAST_SUB)\n",
    "\n",
    "STAI_HEADER     = (\n",
    "  \"Lea cada frase y señale la opción que indique mejor cómo se siente en \"\n",
    "  \"general, en la mayoría de las ocasiones. No hay respuestas buenas ni malas. \"\n",
    "  \"No emplee demasiado tiempo en cada frase y conteste señalando la respuesta \"\n",
    "  \"que mejor describa cómo se siente usted generalmente.\"\n",
    ")\n",
    "STAI_LAST_SUB   = (\n",
    "  \"Cuando pienso sobre asuntos y preocupaciones actuales me pongo tenso y agitado.\"\n",
    ")\n",
    "stai_start_index = find_column_index(subheader_row, STAI_HEADER)\n",
    "stai_end_index   = find_column_index(subsubheader_row, STAI_LAST_SUB)\n",
    "\n",
    "# List of items to reverse-score based on the rule (21, 26, 27, 30, 33, 36, 39 - assuming they are mapped to 0-based column indices)\n",
    "stai_items_to_reverse = [0, 5, 6, 9, 12, 15, 18]\n",
    "\n",
    "BFI_HEADER      = (\n",
    "  \"Por favor, valore cada afirmación del cuestionario en una escala del 1 \"\n",
    "  \"al 5, donde 1 significa \\\"Muy en desacuerdo\\\" y 5 \\\"Muy de acuerdo\\\".\"\n",
    ")\n",
    "BFI_LAST_SUB    = \"Es sofisticado en arte, música o literatura.\"\n",
    "bfi_start_index = find_column_index(subheader_row, BFI_HEADER)\n",
    "bfi_end_index   = find_column_index(subsubheader_row, BFI_LAST_SUB)\n",
    "\n",
    "# Define BFI subscales with scoring\n",
    "# The BFI columns range from 159 (question 1) through 202 (question 44).\n",
    "# Column index for question number q = bfi_start_index + (q - 1)\n",
    "bfi_subscales = {\n",
    "    \"Extraversion\": [bfi_start_index + (q - 1) for q in [1, 6, 11, 16, 21, 26, 31, 36]],\n",
    "    \"Agreeableness\": [bfi_start_index + (q - 1) for q in [2, 7, 12, 17, 22, 27, 32, 37, 42]],\n",
    "    \"Conscientiousness\": [bfi_start_index + (q - 1) for q in [3, 8, 13, 18, 23, 28, 33, 38, 43]],\n",
    "    \"Neuroticism\": [bfi_start_index + (q - 1) for q in [4, 9, 14, 19, 24, 29, 34, 39]],\n",
    "    \"Openness\": [bfi_start_index + (q - 1) for q in [5, 10, 15, 20, 25, 30, 35, 40, 41, 44]],\n",
    "}\n",
    "\n",
    "# Adjust reverse-scored items (R)\n",
    "reverse_scored_items = {\n",
    "    \"Extraversion\": [6, 21, 31],\n",
    "    \"Agreeableness\": [2, 12, 27, 37],\n",
    "    \"Conscientiousness\": [8, 18, 23, 43],\n",
    "    \"Neuroticism\": [9, 24, 34],\n",
    "    \"Openness\": [35, 41],\n",
    "}\n",
    "\n",
    "ASSIST_HEADER     = (\n",
    "  \"A lo largo de la vida, ¿cuál de las siguientes sustancias ha consumido alguna vez? \"\n",
    "  \"(solo que consumió sin receta médica)\"\n",
    ")\n",
    "ASSIST_LAST_HDR   = (\n",
    "  \"¿Alguna vez ha consumido alguna droga por vía inyectada? \"\n",
    "  \"(solo las que consumió sin receta médica)\"\n",
    ")\n",
    "ASSIST_FIRST_SUB  = \"Ninguna de las anteriores\"\n",
    "ASSIST_LAST_SUB   = \"Response\"\n",
    "\n",
    "assist_start_index    = find_column_index(subheader_row, ASSIST_HEADER)\n",
    "assist_end_index      = find_column_index(subheader_row, ASSIST_LAST_HDR)\n",
    "assist_first_sub_idx  = find_column_index(subsubheader_row, ASSIST_FIRST_SUB)\n",
    "assist_last_sub_idx   = find_column_index(subsubheader_row, ASSIST_LAST_SUB)\n",
    "\n",
    "# Question‐1 for substances lives in the column immediately after the ASSIST_HEADER\n",
    "first_substance_index = assist_start_index + 1\n",
    "base_cols             = list(range(first_substance_index,\n",
    "                                   first_substance_index + 9))\n",
    "# 2) read the subheader (row 2) to get each substance name\n",
    "sub_names             = df.iloc[2, base_cols].tolist()  # from subsubheader_row\n",
    "\n",
    "# assist_allowed codes per question number\n",
    "assist_allowed = {\n",
    "    2: {0, 2, 3, 4, 6},\n",
    "    3: {0, 3, 4, 5, 6},\n",
    "    4: {0, 4, 5, 6, 7},\n",
    "    5: {0, 5, 6, 7, 8},\n",
    "    6: {0, 6, 3},\n",
    "    7: {0, 6, 3},\n",
    "}"
   ],
   "id": "8bda71a44ffba477",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Extra_Validation"
    ]
   },
   "cell_type": "markdown",
   "source": [
    " # Test PHQ-9\n",
    "\n",
    "- Every relevant cell has a value between 0 and 3\n",
    "- Column 99 allowed to be empty **TODO What should I do with this ?**"
   ],
   "id": "fdeb3275b4af0f16"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Identify columns where the first row is a number between PHQ_HEADER and PHQ_LAST\n",
    "cols_to_test = list(range(phq_start_index, phq_end_index + 1))\n",
    "\n",
    "# Initialize flag and a list to collect issues\n",
    "passed = True\n",
    "issues = []\n",
    "\n",
    "# Check all cells in rows starting from the 4th row (index 3) in the selected columns\n",
    "for row_index in range(3, df.shape[0]):\n",
    "    for col in cols_to_test:\n",
    "        header_val = float(df.iloc[0, col])\n",
    "        cell = df.iloc[row_index, col]\n",
    "\n",
    "        # Check for NaN/empty cells\n",
    "        if pd.isna(cell):\n",
    "            # For header corresponding to PHQ_LAST (99), an empty cell is acceptable; for others, it's not.\n",
    "            if col == phq_end_index:\n",
    "                continue\n",
    "            else:\n",
    "                issues.append(\n",
    "                    f\"Row {row_index + 1}, Column {col + 1} (header {int(header_val)}) is empty but should have a value between 0 and 3.\")\n",
    "                passed = False\n",
    "        else:\n",
    "            try:\n",
    "                # Convert value to float and check the range\n",
    "                value = float(cell)\n",
    "                if not (0 <= value <= 3):\n",
    "                    issues.append(\n",
    "                        f\"Row {row_index + 1}, Column {col + 1} (header {int(header_val)}) has value {value} not between 0 and 3.\")\n",
    "                    passed = False\n",
    "            except ValueError:\n",
    "                issues.append(\n",
    "                    f\"Row {row_index + 1}, Column {col + 1} (header {int(header_val)}) has non-numeric value: {cell}.\")\n",
    "                passed = False\n",
    "\n",
    "if passed:\n",
    "    print(\"All tests passed: Every relevant cell has a value between 0 and 3 (with the last PHQ column assist_allowed to be empty).\")\n",
    "else:\n",
    "    print(\"Some tests failed:\")\n",
    "    for issue in issues:\n",
    "        print(issue)"
   ],
   "id": "8c28591db8ff9b06",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Extra_Validation"
    ]
   },
   "cell_type": "markdown",
   "source": [
    "# Test OCI -R\n",
    "- Header value '141' found in the first row for OCI-R.\n",
    "- Header value '158' found in the first row for OCI-R.\n",
    "- OCI-R first question header matches expected value.\n",
    "- OCI-R first question subheader matches expected value.\n",
    "- OCI-R last question matches expected value.\n",
    "- All OCI-R cells have valid values between 0 and 4."
   ],
   "id": "7c1491926fd4ebe9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Locate the start and end OCI-R columns using the header row (row 0)\n",
    "try:\n",
    "    start_index = df.iloc[0].tolist().index(\"141\")\n",
    "    print(\"Test passed: Header value '141' found in the first row for OCI-R.\")\n",
    "except ValueError:\n",
    "    raise ValueError(\"Test failed: Header value '141' was not found in the first row of the DataFrame for OCI-R.\")\n",
    "\n",
    "try:\n",
    "    end_index = df.iloc[0].tolist().index(\"158\")\n",
    "    print(\"Test passed: Header value '158' found in the first row for OCI-R.\")\n",
    "except ValueError:\n",
    "    raise ValueError(\"Test failed: Header value '158' was not found in the first row of the DataFrame for OCI-R.\")\n",
    "\n",
    "# Validate the question text.\n",
    "# For the first OCI-R question, we expect (in row 2 if rows are 1-indexed) that\n",
    "# the cell contains \"Acumular cosas hasta el punto que le estorban.\".\n",
    "# %% python\n",
    "EXPECTED_HEADER_QUESTION = \"Escoge la opción que mejor describe CUÁNTO malestar o molestia te ha producido esta experiencia durante el último mes.\"\n",
    "EXPECTED_SUBHEADER_QUESTION = \"Acumular cosas hasta el punto que le estorban.\"\n",
    "\n",
    "# Retrieve the actual questions from the dataframe\n",
    "header_question = df.iloc[1, start_index]\n",
    "subheader_question = df.iloc[2, start_index]\n",
    "\n",
    "# Check if the header and accumulation questions are as expected\n",
    "is_header_incorrect = header_question != EXPECTED_HEADER_QUESTION\n",
    "is_subheader_incorrect = subheader_question != EXPECTED_SUBHEADER_QUESTION\n",
    "\n",
    "if is_header_incorrect:\n",
    "    raise ValueError(\n",
    "        f\"Test failed: OCI-R first question (header '141') does not match the expected header.\\n\"\n",
    "        f\"Found: {header_question}\"\n",
    "    )\n",
    "else:\n",
    "    print(\"Test passed: OCI-R first question header matches expected value.\")\n",
    "\n",
    "if is_subheader_incorrect:\n",
    "    raise ValueError(\n",
    "        f\"Test failed: OCI-R first question (header '141') does not match the expected subheader.\\n\"\n",
    "        f\"Found: {subheader_question}\"\n",
    "    )\n",
    "else:\n",
    "    print(\"Test passed: OCI-R first question subheader matches expected value.\")\n",
    "\n",
    "# For the last OCI-R question, we expect in the third row (index 2) that\n",
    "# the cell contains \"Tener con frecuencia pensamientos repugnantes y que le cueste librarse de ellos.\"\n",
    "if df.iloc[2, end_index] != \"Tener con frecuencia pensamientos repugnantes y que le cueste librarse de ellos.\":\n",
    "    raise ValueError(\n",
    "        f\"Test failed: OCI-R last question (header '158') does not have the expected sentence in the third row. \"\n",
    "        f\"Found: {df.iloc[2, end_index]}\"\n",
    "    )\n",
    "else:\n",
    "    print(\"Test passed: OCI-R last question matches expected value.\")\n",
    "\n",
    "# Check that the answer values for OCI-R (for rows from index 3 onward) are valid (between 0 and 4)\n",
    "oci_issues = []\n",
    "for col in range(start_index, end_index + 1):\n",
    "    header_val = df.iloc[0, col]\n",
    "    for row in range(3, df.shape[0]):\n",
    "        cell = df.iloc[row, col]\n",
    "        try:\n",
    "            value = float(cell)\n",
    "            if not (0 <= value <= 4):\n",
    "                oci_issues.append(\n",
    "                    f\"Row {row + 1}, Column {col + 1} (header {header_val}) has an invalid value: {cell}\"\n",
    "                )\n",
    "        except (ValueError, TypeError):\n",
    "            oci_issues.append(\n",
    "                f\"Row {row + 1}, Column {col + 1} (header {header_val}) cannot be converted to a float: {cell}\"\n",
    "            )\n",
    "\n",
    "if oci_issues:\n",
    "    issues_str = \"\\n\".join(oci_issues)\n",
    "    raise ValueError(\"Test failed: Some OCI-R cells are out of the accepted range or invalid:\\n\" + issues_str)\n",
    "else:\n",
    "    print(\"Test passed: All OCI-R cells have valid values between 0 and 4.\")"
   ],
   "id": "bc7186bda7b020eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Extra_Validation"
    ]
   },
   "cell_type": "markdown",
   "source": "# Test BAI",
   "id": "8d58d577021da06d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Locate the start and end BAI columns using the header row (row 0)\n",
    "try:\n",
    "    start_index = df.iloc[0].tolist().index(\"120\")\n",
    "    print(\"Test passed: Header value '120' found in the first row for BAI.\")\n",
    "except ValueError:\n",
    "    raise ValueError(\"Test failed: Header value '120' was not found in the first row of the DataFrame for BAI.\")\n",
    "\n",
    "try:\n",
    "    end_index = df.iloc[0].tolist().index(\"140\")\n",
    "    print(\"Test passed: Header value '140' found in the first row for BAI.\")\n",
    "except ValueError:\n",
    "    raise ValueError(\"Test failed: Header value '140' was not found in the first row of the DataFrame for BAI.\")\n",
    "\n",
    "# Validate the header and subheader texts\n",
    "EXPECTED_BAI_HEADER = \"En el cuestionario hay una lista de síntomas comunes de la ansiedad. Lea cada uno de los ítems atentamente, e indique cuanto le ha afectado en la última semana incluyendo hoy:\"\n",
    "EXPECTED_BAI_FIRST_SUBHEADER = \"Torpe o entumecido.\"\n",
    "EXPECTED_BAI_LAST_SUBHEADER = \"Con sudores, fríos o calientes.\"\n",
    "\n",
    "# Retrieve the actual header and subheader questions\n",
    "bai_header_question = df.iloc[1, start_index]\n",
    "bai_first_subheader = df.iloc[2, start_index]\n",
    "bai_last_subheader = df.iloc[2, end_index]\n",
    "\n",
    "# Check if the header and subheaders are as expected\n",
    "if bai_header_question != EXPECTED_BAI_HEADER:\n",
    "    raise ValueError(\n",
    "        f\"Test failed: BAI first question (header '120') does not match the expected header.\\n\"\n",
    "        f\"Found: {bai_header_question}\"\n",
    "    )\n",
    "else:\n",
    "    print(\"Test passed: BAI header matches expected value.\")\n",
    "\n",
    "if bai_first_subheader != EXPECTED_BAI_FIRST_SUBHEADER:\n",
    "    raise ValueError(\n",
    "        f\"Test failed: BAI first question (header '120') does not match the expected first subheader.\\n\"\n",
    "        f\"Found: {bai_first_subheader}\"\n",
    "    )\n",
    "else:\n",
    "    print(\"Test passed: BAI first subheader matches expected value.\")\n",
    "\n",
    "if bai_last_subheader != EXPECTED_BAI_LAST_SUBHEADER:\n",
    "    raise ValueError(\n",
    "        f\"Test failed: BAI last question (header '140') does not match the expected last subheader.\\n\"\n",
    "        f\"Found: {bai_last_subheader}\"\n",
    "    )\n",
    "else:\n",
    "    print(\"Test passed: BAI last subheader matches expected value.\")\n",
    "\n",
    "# Check that the answer values for BAI (for rows from index 4 onward) are valid (between 0 and 4)\n",
    "bai_issues = []\n",
    "for col in range(start_index, end_index + 1):\n",
    "    header_val = df.iloc[0, col]\n",
    "    for row in range(4, df.shape[0]):\n",
    "        cell = df.iloc[row, col]\n",
    "        try:\n",
    "            value = float(cell)\n",
    "            if not (0 <= value <= 4):\n",
    "                bai_issues.append(\n",
    "                    f\"Row {row + 1}, Column {col + 1} (header {header_val}) has an invalid value: {cell}\"\n",
    "                )\n",
    "        except (ValueError, TypeError):\n",
    "            bai_issues.append(\n",
    "                f\"Row {row + 1}, Column {col + 1} (header {header_val}) cannot be converted to a float: {cell}\"\n",
    "            )\n",
    "\n",
    "if bai_issues:\n",
    "    issues_str = \"\\n\".join(bai_issues)\n",
    "    raise ValueError(\"Test failed: Some BAI cells are out of the accepted range or invalid:\\n\" + issues_str)\n",
    "else:\n",
    "    print(\"Test passed: All BAI cells have valid values between 0 and 4.\")"
   ],
   "id": "625e4cd7381c35c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Extra_Validation"
    ]
   },
   "cell_type": "markdown",
   "source": "# Test STAI",
   "id": "dc6f2f84a4d92a77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Locate the start and end STAI columns using the header row (row 0)\n",
    "start_index = find_column_index(df.iloc[0], \"100\")\n",
    "end_index = find_column_index(df.iloc[0], \"119\")\n",
    "\n",
    "# Validate the STAI header and subheader\n",
    "EXPECTED_STAI_HEADER = \"Lea cada frase y señale la opción que indique mejor cómo se siente en general, en la mayoría de las ocasiones. No hay respuestas buenas ni malas. No emplee demasiado tiempo en cada frase y conteste señalando la respuesta que mejor describa cómo se siente usted generalmente.\"\n",
    "EXPECTED_STAI_SUBHEADER = \"Cuando pienso sobre asuntos y preocupaciones actuales me pongo tenso y agitado.\"\n",
    "\n",
    "stai_header_question = df.iloc[1, start_index]\n",
    "stai_subheader = df.iloc[2, end_index]\n",
    "\n",
    "if stai_header_question != EXPECTED_STAI_HEADER:\n",
    "    raise ValueError(f\"Test failed: STAI header does not match the expected value.\\nFound: {stai_header_question}\")\n",
    "else:\n",
    "    print(\"Test passed: STAI header matches expected value.\")\n",
    "\n",
    "if stai_subheader != EXPECTED_STAI_SUBHEADER:\n",
    "    raise ValueError(f\"Test failed: STAI subheader does not match the expected value.\\nFound: {stai_subheader}\")\n",
    "else:\n",
    "    print(\"Test passed: STAI subheader matches expected value.\")\n",
    "\n",
    "# Check that the values for STAI (for rows from index 4 onward) are valid (between 0 and 3)\n",
    "stai_issues = []\n",
    "for col in range(start_index, end_index + 1):\n",
    "    header_val = df.iloc[0, col]\n",
    "    for row in range(4, df.shape[0]):\n",
    "        cell = df.iloc[row, col]\n",
    "        try:\n",
    "            value = float(cell)\n",
    "            if not (0 <= value <= 3):\n",
    "                stai_issues.append(\n",
    "                    f\"Row {row + 1}, Column {col + 1} (header {header_val}) has an invalid value: {cell}\"\n",
    "                )\n",
    "        except (ValueError, TypeError):\n",
    "            stai_issues.append(\n",
    "                f\"Row {row + 1}, Column {col + 1} (header {header_val}) cannot be converted to a float: {cell}\"\n",
    "            )\n",
    "\n",
    "if stai_issues:\n",
    "    raise ValueError(\"Test failed: Some STAI cells are out of the accepted range or invalid:\\n\" + \"\\n\".join(stai_issues))\n",
    "else:\n",
    "    print(\"Test passed: All STAI cells have valid values between 0 and 3.\")"
   ],
   "id": "a1dc4eda2044acd5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Extra_Validation"
    ]
   },
   "cell_type": "markdown",
   "source": "# Test BFI",
   "id": "41a53d9c27b3d70f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Locate the start and end BFI columns using the header row (row 0)\n",
    "try:\n",
    "    start_index = df.iloc[0].tolist().index(\"159\")\n",
    "    print(\"Test passed: Header value '159' found in the first row for BFI.\")\n",
    "except ValueError:\n",
    "    raise ValueError(\"Test failed: Header value '159' was not found in the first row of the DataFrame for BFI.\")\n",
    "\n",
    "try:\n",
    "    end_index = df.iloc[0].tolist().index(\"202\")\n",
    "    print(\"Test passed: Header value '202' found in the first row for BFI.\")\n",
    "except ValueError:\n",
    "    raise ValueError(\"Test failed: Header value '202' was not found in the first row of the DataFrame for BFI.\")\n",
    "\n",
    "# Validate the question text\n",
    "EXPECTED_BFI_HEADER = \"Por favor, valore cada afirmación del cuestionario en una escala del 1 al 5, donde 1 significa \\\"Muy en desacuerdo\\\" y 5 \\\"Muy de acuerdo\\\".\"\n",
    "EXPECTED_BFI_LAST_SUBHEADER = \"Es sofisticado en arte, música o literatura.\"\n",
    "\n",
    "header_question = df.iloc[1, start_index]\n",
    "subheader_question = df.iloc[2, end_index]\n",
    "\n",
    "if header_question != EXPECTED_BFI_HEADER:\n",
    "    raise ValueError(f\"Test failed: BFI initial header does not match the expected value.\\nFound: {header_question}\")\n",
    "else:\n",
    "    print(\"Test passed: BFI header matches expected value.\")\n",
    "\n",
    "if subheader_question != EXPECTED_BFI_LAST_SUBHEADER:\n",
    "    raise ValueError(f\"Test failed: BFI last subheader does not match the expected value.\\nFound: {subheader_question}\")\n",
    "else:\n",
    "    print(\"Test passed: BFI last subheader matches expected value.\")\n",
    "\n",
    "# Check that the answer values for BFI (for rows from index 4 onward) are valid (between 1 and 5)\n",
    "bfi_issues = []\n",
    "for col in range(start_index, end_index + 1):\n",
    "    header_val = df.iloc[0, col]\n",
    "    for row in range(3, df.shape[0]):\n",
    "        cell = df.iloc[row, col]\n",
    "        try:\n",
    "            value = float(cell)\n",
    "            if not (1 <= value <= 5):\n",
    "                bfi_issues.append(\n",
    "                    f\"Row {row + 1}, Column {col + 1} (header {header_val}) has an invalid value: {cell}\"\n",
    "                )\n",
    "        except (ValueError, TypeError):\n",
    "            bfi_issues.append(\n",
    "                f\"Row {row + 1}, Column {col + 1} (header {header_val}) cannot be converted to a float: {cell}\"\n",
    "            )\n",
    "\n",
    "if bfi_issues:\n",
    "    issues_str = \"\\n\".join(bfi_issues)\n",
    "    raise ValueError(\"Test failed: Some BFI cells are out of the accepted range or invalid:\\n\" + issues_str)\n",
    "else:\n",
    "    print(\"Test passed: All BFI cells have valid values between 1 and 5.\")"
   ],
   "id": "1be45f9d29ef0bdb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# TEST ASSIST",
   "id": "30652c10dc93d291"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for r in range(3, df.shape[0]):\n",
    "    # Special case if \"Ninguna de las anteriores\"\n",
    "    if pd.notna(df.iat[r, assist_first_sub_idx]) and int(df.iat[r, assist_first_sub_idx]) == 0:\n",
    "        if not df.iloc[r][first_substance_index:assist_end_index].isna().all():\n",
    "            subset = df.iloc[r][first_substance_index:assist_end_index]\n",
    "            not_na = subset[~subset.isna()]\n",
    "            raise ValueError(f\"Not all values of row {r} between columns {first_substance_index} and {assist_end_index} are NaN: {not_na.to_dict()}\")\n",
    "        continue\n",
    "    for c in range(assist_start_index, assist_start_index + 9):\n",
    "        val = df.iat[r, c]\n",
    "        header = df.iat[2, c]\n",
    "        if pd.notna(val):\n",
    "            if header != \"Otro (especifique)\":\n",
    "                # If the “next” question is 0, zero out the three follow-ups\n",
    "                if int(df.iat[r, c + 9]) == 0:\n",
    "                    df.iat[r, c + 18] = df.iat[r, c + 27] = df.iat[r, c + 36] = 0\n",
    "                # Checking all the values for each specific substance (i.e. every next 9 columns)\n",
    "                for qnum, allowed_vals in assist_allowed.items():\n",
    "                    sc = c + 9 * (qnum - 1)  # substance column\n",
    "                    resp = int(df.iat[r, sc])\n",
    "                    if resp in allowed_vals:\n",
    "                        continue\n",
    "                    else:\n",
    "                        raise ValueError(\n",
    "                            f\"In Question {qnum}, Column {sc} found: {resp}\\n\"\n",
    "                            f\"assist_allowed Values are: {allowed_vals}\"\n",
    "                        )\n",
    "# Skip value validation as per the user's request\n",
    "print(\"Passed ASSIST value validation.\")"
   ],
   "id": "ecd02c35b2d2278e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Results ASSIST",
   "id": "79cb7196cdeaaeb3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# prepare to collect per-user dicts\n",
    "results = []\n",
    "for r in range(3, df.shape[0]):\n",
    "    username = df.iat[r, user_col_index]\n",
    "    rec = {\"username\": username}\n",
    "\n",
    "    for c, name in zip(base_cols, sub_names):\n",
    "        offsets = [9*i for i in range(1,7)]       # Q2–Q7\n",
    "        if name.startswith(\"Tabaco\"):\n",
    "            offsets.remove(36)                    # drop Q5\n",
    "        total = sum(int(df.iat[r, c+off])       # NaN→skip\n",
    "                    for off in offsets\n",
    "                    if pd.notna(df.iat[r, c+off]))\n",
    "        rec[name] = total\n",
    "\n",
    "    results.append(rec)\n",
    "assist_scores_df = pd.DataFrame(results)\n",
    "\n",
    "low_max = {\n",
    "  \"Tabaco (cigarrillos, tabaco de mascar, puros, etc.)\": 3,\n",
    "  \"Alcohol\": 10,\n",
    "}\n",
    "moderate_max = 26\n",
    "\n",
    "for col in assist_scores_df.columns:\n",
    "    if col == \"username\": continue\n",
    "    lo   = low_max.get(col, 3)\n",
    "    sc   = assist_scores_df[col]\n",
    "    masks = [\n",
    "      sc <= lo,\n",
    "      sc.between(lo+1, moderate_max),\n",
    "      sc >= (moderate_max+1),\n",
    "    ]\n",
    "    labels = [\n",
    "      \"No requiere intervención\",\n",
    "      \"Recibir intervención breve\",\n",
    "      \"Tratamiento más intensivo\",\n",
    "    ]\n",
    "    #assist_scores_df[f\"{col}_risk\"] = np.select(masks, labels, default=np.nan)\n",
    "    assist_scores_df[f\"{col}_risk\"] = np.select(masks, labels, default=\"Unknown\")\n",
    "\n",
    "\n",
    "# 3) inspect\n",
    "assist_scores_df.head(6)"
   ],
   "id": "bb9f5ca0b54c1f76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# TOTAL RESULTS",
   "id": "8cc6585fae3a3dd6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# list of your 9 substance names (exactly as columns in assist_scores_df)\n",
    "#sub_names = [col for col in assist_scores_df.columns if not col.endswith(\"_risk\") and col != \"username\"]\n",
    "\n",
    "df = df.merge(\n",
    "  assist_scores_df,\n",
    "  left_on = df.columns[user_col_index],\n",
    "  right_on= \"username\",\n",
    "  how      = \"left\"\n",
    ")\n",
    "\n",
    "# pick up all substance names dynamically:\n",
    "sub_names = [c for c in assist_scores_df.columns\n",
    "             if c!=\"username\" and not c.endswith(\"_risk\")]\n",
    "\n",
    "# Iterate through each user (rows starting from index 3)\n",
    "for idx in range(3, df.shape[0]):\n",
    "    row = df.iloc[idx]\n",
    "    username = row[user_col_index]\n",
    "\n",
    "    # Convert responses for each test to float and sum\n",
    "    try:\n",
    "        phq_scores = row[phq_start_index:phq_end_index + 1].astype(float)\n",
    "        phq_total = int(phq_scores.sum())\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error processing PHQ responses for user '{username}' on row {idx + 1}: {e}\")\n",
    "\n",
    "    try:\n",
    "        bai_scores = row[bai_start_index:bai_end_index + 1].astype(float)\n",
    "        bai_total = int(bai_scores.sum())\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error processing BAI responses for user '{username}' on row {idx + 1}: {e}\")\n",
    "\n",
    "    try:\n",
    "        oci_scores = row[oci_start_index:oci_end_index + 1].astype(float)\n",
    "        oci_total = int(oci_scores.sum())\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error processing OCI responses for user '{username}' on row {idx + 1}: {e}\")\n",
    "\n",
    "    # Process STAI results\n",
    "    try:\n",
    "        stai_scores = row[stai_start_index:stai_end_index + 1].astype(float)\n",
    "        for item in stai_items_to_reverse:\n",
    "            col_to_reverse = stai_start_index + item\n",
    "            if not pd.isna(row[col_to_reverse]):  # Check if the value is not NaN\n",
    "                stai_scores.iloc[item] = 3 - int(stai_scores.iloc[item])\n",
    "        stai_total = int(stai_scores.sum())\n",
    "        sex = row[sex_col_index]  # Fetch gender (if data is present)\n",
    "        if sex == \"2\" and stai_total >= 29:\n",
    "            stai_classification = \"High\"\n",
    "        elif sex == \"1\" and stai_total >= 37:\n",
    "            stai_classification = \"High\"\n",
    "        elif sex == \"3\":\n",
    "            stai_classification = \"Binary\"\n",
    "        else:\n",
    "            stai_classification = \"Normal\"\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error processing STAI responses for user '{username}' on row {idx + 1}: {e}\")\n",
    "\n",
    "    # Process BFI scores\n",
    "    try:\n",
    "        bfi_scores = {}\n",
    "        for subscale, cols in bfi_subscales.items():\n",
    "            score = 0\n",
    "            for col in cols:\n",
    "                cell_value = row[col]\n",
    "                try:\n",
    "                    value = float(cell_value)\n",
    "\n",
    "                    # Reverse the score if the question is reverse scored\n",
    "                    if col - bfi_start_index + 1 in reverse_scored_items.get(subscale, []):\n",
    "                        value = 6 - value  # Reverse score: 1 <-> 5, 2 <-> 4, 3 remains 3\n",
    "\n",
    "                    score += value\n",
    "                except ValueError:\n",
    "                    raise ValueError(f\"Error processing BFI responses for user '{username}' on column {col}: {cell_value}\")\n",
    "            bfi_scores[subscale] = round(score/len(cols), 2)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error processing BFI responses for user '{username}' on row {idx + 1}: {e}\")\n",
    "\n",
    "    # Classify PHQ scores based on depression severity\n",
    "    if phq_total < 5:\n",
    "        phq_classification = \"minimal depression\"\n",
    "    elif phq_total < 10:\n",
    "        phq_classification = \"mild depression\"\n",
    "    elif phq_total < 15:\n",
    "        phq_classification = \"moderate depression\"\n",
    "    elif phq_total < 20:\n",
    "        phq_classification = \"moderately severe depression\"\n",
    "    else:\n",
    "        phq_classification = \"severe depression\"\n",
    "\n",
    "    # Classify BAI scores\n",
    "    if bai_total <= 21:\n",
    "        bai_classification = \"low anxiety\"\n",
    "    elif bai_total <= 35:\n",
    "        bai_classification = \"moderate anxiety\"\n",
    "    else:\n",
    "        bai_classification = \"potentially concerning levels of anxiety\"\n",
    "\n",
    "    # If OCI total is greater than or equal to 21, indicate that the user has OCD.\n",
    "    if oci_total >= 21:\n",
    "        oci_classification = \"has OCD\"\n",
    "    else:\n",
    "        oci_classification = \"does not have OCD\"\n",
    "\n",
    "    # Put results in df\n",
    "\n",
    "    df.at[idx, \"phq_total\"]          = phq_total\n",
    "    df.at[idx, \"phq_classification\"] = phq_classification\n",
    "\n",
    "    df.at[idx, \"oci_total\"]          = oci_total\n",
    "    df.at[idx, \"oci_classification\"] = oci_classification\n",
    "\n",
    "    df.at[idx, \"bai_total\"]          = bai_total\n",
    "    df.at[idx, \"bai_classification\"] = bai_classification\n",
    "\n",
    "    df.at[idx, \"stai_total\"]         = stai_total\n",
    "    df.at[idx, \"stai_classification\"]= stai_classification\n",
    "\n",
    "    # BFI subscales\n",
    "    for subscale, score in bfi_scores.items():\n",
    "        df.at[idx, f\"BFI_{subscale}\"] = score\n",
    "\n",
    "    # ASSIST fragment:\n",
    "    assist_parts = [\n",
    "      f\"{sub}={row[sub]} ({row[f'{sub}_risk']})\"\n",
    "      for sub in sub_names\n",
    "    ]\n",
    "    assist_report = \"; \".join(assist_parts)\n",
    "\n",
    "    # Prepare the report string including STAI classification\n",
    "    report = (\n",
    "        f\"{username}: PHQ Total = {phq_total} ({phq_classification}), \"\n",
    "        f\"OCI Total = {oci_total} ({oci_classification}), \"\n",
    "        f\"BAI Total = {bai_total} ({bai_classification}), \"\n",
    "        f\"STAI Total = {stai_total} ({stai_classification}), \"\n",
    "        f\"BFI Scores = {bfi_scores}, \"\n",
    "        f\"ASSIST → {assist_report}\"\n",
    "    )\n",
    "    print(report)"
   ],
   "id": "f4239923ea192151",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "responses_df = df[3:]\n",
    "\n",
    "# Remove rows containing specific usernames\n",
    "usernames_to_remove = ['1XIH2', 'B1Q2C', 'QO12D']\n",
    "responses_df = responses_df[~responses_df.iloc[:, user_col_index].isin(usernames_to_remove)]\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"username\": responses_df.iloc[:, user_col_index],\n",
    "    \"gender\": responses_df.iloc[:, sex_col_index],\n",
    "    \"phq_total\": responses_df[\"phq_total\"],\n",
    "    \"phq_classification\": responses_df[\"phq_classification\"],\n",
    "    \"oci_total\": responses_df[\"oci_total\"],\n",
    "    \"oci_classification\": responses_df[\"oci_classification\"],\n",
    "    \"bai_total\": responses_df[\"bai_total\"],\n",
    "    \"bai_classification\": responses_df[\"bai_classification\"],\n",
    "    \"stai_total\": responses_df[\"stai_total\"],\n",
    "    \"stai_classification\": responses_df[\"stai_classification\"],\n",
    "    # Add any additional assist columns here if needed (example):\n",
    "    # \"assist_column\": responses_df[\"assist_column_name\"]\n",
    "})\n",
    "\n",
    "# Filter and extract all columns starting with \"BFI_\"\n",
    "bfi_columns = responses_df.filter(regex=r\"^BFI_\")\n",
    "\n",
    "# Concatenate the filtered BFI columns to the main results DataFrame\n",
    "results_df = pd.concat([results_df, bfi_columns], axis=1)\n",
    "\n",
    "results_df = results_df.merge(assist_scores_df, on='username', how='left')\n",
    "\n",
    "# --- 3. Export the results ---\n",
    "results_df.to_excel(\"results_surveyMonkey_Processed.xlsx\", index=False)\n",
    "results_df.to_csv(\"results_surveyMonkey_Processed.csv\", index=False)\n",
    "\n",
    "print(\"Results exported to 'results.xlsx' and 'results.csv'.\")"
   ],
   "id": "917c4d2b466185a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Visualizations",
   "id": "399f1527a2b050d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Option 1: use DataFrame.filter with a regex\n",
    "# Option B: single-filter regex\n",
    "# Option C: boolean mask\n",
    "mask = responses_df.columns.str.startswith('BFI') | df.columns.str.startswith('username')\n",
    "df.loc[3:, mask].head(10)"
   ],
   "id": "5b0590a62450f75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sex_codes = df.loc[3:, sex_col_index].dropna().astype(int)\n",
    "gender_map = {1: \"Female\", 2: \"Male\", 3: \"Non-binary\"}\n",
    "genders = sex_codes.map(gender_map)\n",
    "\n",
    "order = [\"Female\", \"Male\", \"Non-binary\"]\n",
    "counts = genders.value_counts().reindex(order, fill_value=0)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(counts.index, counts.values, edgecolor='black')\n",
    "plt.title(\"Gender Distribution of Respondents\")\n",
    "plt.ylabel(\"Number of Users\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "91974526e5b96540",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Make sure these columns exist (you can do this before the loop)\n",
    "new_cols = [\n",
    "  \"phq_total\",\"phq_classification\",\n",
    "  \"oci_total\",\"oci_classification\",\n",
    "  \"bai_total\",\"bai_classification\",\n",
    "  \"stai_total\",\"stai_classification\"\n",
    "] + [f\"BFI_{sub}\" for sub in bfi_subscales]\n",
    "# plus all ASSIST score and risk columns are already in df from the merge\n",
    "# Numeric totals\n",
    "\n",
    "# assemble totals into one DataFrame\n",
    "totals = df.loc[3:, [f for f in ['phq_total','bai_total','oci_total','stai_total']]].astype(int)\n",
    "print(totals)\n",
    "plt.figure(figsize=(10,6))\n",
    "for i, col in enumerate(totals.columns, 1):\n",
    "    plt.subplot(2,2,i)\n",
    "    plt.hist(totals[col], bins=12, edgecolor='black')\n",
    "    plt.title(col.replace('_',' ').upper())\n",
    "    plt.xlabel('Score')\n",
    "    plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "77c15d1f8933abbd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# List of your classification columns and plot titles\n",
    "class_cols = [\n",
    "    'phq_classification',\n",
    "    'bai_classification',\n",
    "    'oci_classification',\n",
    "    'stai_classification'\n",
    "]\n",
    "titles = [\n",
    "    'PHQ-9 Depression Severity',\n",
    "    'BAI Anxiety Level',\n",
    "    'OCI-R OCD Classification',\n",
    "    'STAI Anxiety Classification'\n",
    "]\n",
    "\n",
    "# Make the 2×2 plot\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, col, title in zip(axes, class_cols, titles):\n",
    "    # count each category\n",
    "    counts = df.loc[3:, col].value_counts().sort_index()\n",
    "    ax.bar(counts.index, counts.values, edgecolor='black')\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel('Number of Users')\n",
    "    ax.tick_params(axis='x', rotation=45, labelsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "9afdd3cbe9b18086",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.boxplot([totals[c] for c in totals.columns], tick_labels=[c.upper() for c in totals.columns])\n",
    "plt.title(\"Comparison of Total Scores\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.show()"
   ],
   "id": "6aa2c310f49eb6fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# reshape into long form\n",
    "assist_long = assist_scores_df.melt(id_vars='username',\n",
    "    value_vars=sub_names,\n",
    "    var_name='sustancia', value_name='score'\n",
    ").merge(\n",
    "    assist_scores_df.melt(id_vars='username',\n",
    "        value_vars=[f\"{s}_risk\" for s in sub_names],\n",
    "        var_name='tmp', value_name='risk'\n",
    "    ).assign(sustancia=lambda d: d['tmp'].str.replace('_risk',''))[['username','sustancia','risk']],\n",
    "    on=['username','sustancia']\n",
    ")\n",
    "\n",
    "# Filter out individuals with a score of 0 on the sustancias\n",
    "assist_long_filtered = assist_long[assist_long['score'] > 0]\n",
    "\n",
    "# count\n",
    "#counts = assist_long.groupby(['sustancia','risk']).size().unstack(fill_value=0)\n",
    "counts = assist_long_filtered.groupby(['sustancia','risk']).size().unstack(fill_value=0)\n",
    "\n",
    "counts.plot(kind='bar', stacked=True, figsize=(10,6))\n",
    "plt.ylabel(\"Número de usuarios\")\n",
    "plt.title(\"Distribución de categorías de riesgo ASSIST por sustancia\")\n",
    "plt.legend(title=\"Riesgo\", bbox_to_anchor=(1,1))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "ce4528c70ae8077",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# assuming you've merged bfi subscale columns (Extraversion, Agreeableness, …) into df\n",
    "bfi_cols = [\"BFI_Extraversion\",\"BFI_Agreeableness\",\"BFI_Conscientiousness\",\n",
    "            \"BFI_Neuroticism\",\"BFI_Openness\"]\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.boxplot(\n",
    "    [df.loc[3:, trait].astype(float) for trait in bfi_cols],\n",
    "    tick_labels=bfi_cols,\n",
    "    notch=True\n",
    ")\n",
    "plt.xticks(rotation=15)\n",
    "plt.ylabel(\"Mean Score\")\n",
    "plt.title(\"BFI Subscale Distributions\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "8d792843383eb9f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# collect a numeric matrix\n",
    "num_cols = [\"phq_total\",\"bai_total\",\"oci_total\",\"stai_total\"] + bfi_cols\n",
    "mat = df.loc[3:, num_cols].astype(float).corr()\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "im = plt.imshow(mat, aspect=\"auto\")\n",
    "plt.colorbar(im)\n",
    "plt.xticks(range(len(num_cols)), num_cols, rotation=45, ha=\"right\")\n",
    "plt.yticks(range(len(num_cols)), num_cols)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "# annotate the cells\n",
    "for i in range(len(num_cols)):\n",
    "    for j in range(len(num_cols)):\n",
    "        plt.text(j, i, f\"{mat.iat[i,j]:.2f}\", ha=\"center\", va=\"center\", fontsize=8, color=\"white\" if abs(mat.iat[i,j])>0.5 else \"black\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "ae74267dd9a157b8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
